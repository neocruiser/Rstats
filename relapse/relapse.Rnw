\documentclass[9pt,english]{extarticle}
\include{canevas_config}

\begin{document}
{
  \centering
  {\bf \large Summary statistics: Lymphoma predictive modeling\\}
  {\bf Sleiman Bassim, PhD\\}
  \medskip
  {Project started in December 2017\\}
  {Original version published in August 2018\\}
  {Last updated on \today}

}
%\maketitle
<<setup, include=FALSE, cache=FALSE>>=
# set global chunk options
opts_chunk$set(dev="postscript",
               fig.path="graphics/",
               fig.lp= "",
               comment=NA,
               fig.keep="high",
               fig.show='hold',
               fig.align='center', 
               out.width='.49\\textwidth',
               tidy.source=TRUE,
               crop=TRUE,
               results="markup",
               warnings=FALSE,
               error=FALSE,
               message=FALSE)
options(formatR.arrow=TRUE,
        width=70,
        digits = 3,
        scipen = 6)
@ 


%\maketitle
\tableofcontents
\pagebreak

\begin{linenumbers}
\noindent

Loading packages.
<<packages,results='hide'>>=
pkgs <- c('gdata','lattice','latticeExtra',
          'ggplot2', 'dplyr', 'tidyr', 'RColorBrewer','igraph',
          'DescTools', 'scales', 'brotools', 'Hmisc', 'finalfit',
          'plyr', 'paletteer', 'ggrepel', 'ggExtra', 'ggpubr',
          'cowplot', 'ggridges', 'reshape')
lapply(pkgs, require, character.only = TRUE)
@


\section{Exploratory Data Analysis}
\label{sec:structure}
Data is from individuals with Lymphoma tumors, either undergone or not a Rituximab CHOP treatment. Some individuals show relapse after treatment. Tumors migrate though nodal (lymphnodes) or extranodal tissues. Tumors involve two different subtypes of cells of origin, ABC or GCB. \textbf{The first aim is to find correlation genes that respond differently to treatment, nodal transmission, and cell subtypes.}
\marginnote{\small\color{blue}$\Lsh$OR: Odds ratio. HR: Hazard ratio}[0cm]
<<summary_full>>=
#read.table("data/phenodata", sep = "\t", header = T) %>%
#    dplyr::select(SAMPLE_ID, Timepoint, 
#    GROUP, SITE, Score, Prediction, ABClikelihood) %>%
#    brotools::describe()

print_summary_table <- function(features, dependent, df, execute = TRUE) {
    if ( execute == TRUE ) {
        x <- df %>%
            summary_factorlist(dependent, features, p=FALSE, add_dependent_label=TRUE)
        ## print latex table
        Hmisc::latex(x, file = "", booktabs = TRUE, title = "")
    } else {
        cat("LaTeX summary table printed\n")
    }
}

dfs <- read.table("data/phenodata", sep = "\t", header = T)
print_summary_table(features= c("Score", "ABClikelihood", "GROUP"), 
                    dependent= c("Prediction"), 
                    df = dfs, 
                    execute = F)
@ 


\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-2pt}
\begin{tabular}{llllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Prediction}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{ABC}&\multicolumn{1}{c}{GCB}&\multicolumn{1}{c}{U}\tabularnewline
\midrule
10&Score&Mean (SD)&3156.3 (475.5)&506.4 (721.1)&2162.8 (143.6)\tabularnewline
1&ABClikelihood&Mean (SD)&1 (0)&0 (0)&0.5 (0.4)\tabularnewline
2&GROUP&CNS DIAGNOSIS&4 (33.3)&6 (50.0)&2 (16.7)\tabularnewline
3&&CNS RELAPSE CHOP or EQUIVALENT&6 (60.0)&3 (30.0)&1 (10.0)\tabularnewline
4&&CNS RELAPSE RCHOP&17 (44.7)&13 (34.2)&8 (21.1)\tabularnewline
5&&NO RELAPSE&27 (28.1)&52 (54.2)&17 (17.7)\tabularnewline
6&&NORMAL ABC CONTROL&2 (100.0)&0 (0.0)&0 (0.0)\tabularnewline
7&&NORMAL GCB CONTROL&0 (0.0)&4 (100.0)&0 (0.0)\tabularnewline
8&&SYTEMIC RELAPSE NO CNS&31 (48.4)&25 (39.1)&8 (12.5)\tabularnewline
9&&TESTICULAR NO CNS RELAPSE&9 (75.0)&0 (0.0)&3 (25.0)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}


\subsection{Data reformating}
\label{subsec:reformating}

In the first steps of the analysis, the samples will be labeled (supervised) into the following categories (based on patients diagnosis).
<<summary_selected>>=
metadata <- read.table("data/phenodata", sep = "\t", header = T) %>%
    dplyr::select(SAMPLE_ID, Timepoint, GROUP, SITE, Score, Prediction, ABClikelihood) %>%
    filter(Timepoint != "T2") %>%
    mutate(Groups = case_when(GROUP %in% c("CNS_RELAPSE_RCHOP",
                                            "CNS_RELAPSE_CHOPorEQUIVALENT",
                                            "CNS_DIAGNOSIS") ~ "CNS",
                               GROUP %in% c("TESTICULAR_NO_CNS_RELAPSE", "NO_RELAPSE") ~ "NOREL",
                               GROUP == "SYTEMIC_RELAPSE_NO_CNS" ~ "SYST",
                               TRUE ~ "CTRL")) %>%
    filter(Groups != "CTRL") %>%
    mutate(ABClassify = case_when(ABClikelihood >= .9 ~ "ABC",
                                  ABClikelihood <= .1 ~ "GCB",
                                  TRUE ~ "U")) %>%
    mutate(ABCScore = case_when(Score > 2412 ~ "ABC",
                                Score <= 1900 ~ "GCB",
#                                Score == NA ~ "NA",
                                TRUE ~ "U")) %>%
    mutate(Nodes = case_when(SITE == "LN" ~ "LN",
                             SITE == "TO" ~ "LN",
                             SITE == "SP" ~ "LN",
                             TRUE ~ "EN")) %>%
    mutate(Lymphnodes = case_when(Nodes == "LN" ~ 1, TRUE ~ 0))

# factorize
metadata$Groups <- as.factor(metadata$Groups)
metadata$ABClassify <- as.factor(metadata$ABClassify)
metadata$ABCScore <- as.factor(metadata$ABCScore)
metadata$Nodes <- as.factor(metadata$Nodes)
metadata$Lymphnodes <- as.factor(metadata$Lymphnodes)

## reorder sample names
ids <- read.table("data/sampleIDs")
metadata <- arrange(metadata, factor(SAMPLE_ID, levels = ids$V1))
meta.selected <- metadata %>%
    mutate(Contrast1 = as.factor(paste0(Groups, ".", Prediction))) %>%
    mutate(Contrast2 = as.factor(paste0(Groups, ".", Nodes)))

#brotools::describe(metadata)
print_summary_table(c("ABCScore", "ABClassify", "GROUP", 
                      "Contrast1", "Contrast2"), c("Nodes"), meta.selected, execute = F)
@ 

\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-2pt}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}\tabularnewline
\midrule
4&ABCScore&ABC&34 (37.0)&58 (63.0)\tabularnewline
5&&GCB&36 (35.0)&67 (65.0)\tabularnewline
6&&U&16 (39.0)&25 (61.0)\tabularnewline
1&ABClassify&ABC&37 (35.9)&66 (64.1)\tabularnewline
2&&GCB&38 (32.5)&79 (67.5)\tabularnewline
3&&U&11 (68.8)&5 (31.2)\tabularnewline
7&GROUP&CNS DIAGNOSIS&7 (63.6)&4 (36.4)\tabularnewline
8&&CNS RELAPSE CHOP or EQUIVALENT&5 (62.5)&3 (37.5)\tabularnewline
9&&CNS RELAPSE RCHOP&20 (51.3)&19 (48.7)\tabularnewline
10&&NO RELAPSE&30 (31.2)&66 (68.8)\tabularnewline
11&&NORMAL ABC CONTROL&2 (NA)&0 (0.0)\tabularnewline
12&&NORMAL GCB CONTROL&0 (0.0)&4 (100.0)\tabularnewline
13&&SYTEMIC RELAPSE NO CNS&10 (15.6)&54 (84.4)\tabularnewline
14&&TESTICULAR NO CNS RELAPSE&12 (100.0)&0 (0.0)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}


\subsubsection{On-array content of non-coding RNA}
\label{subsec:ncrna}
One microarray contains 70,524 probes, of which 12,969 genes do not contain any of the terms related to non-coding RNAs. The graph shows in red that the coding genes are categorized as mRNA or RNA. The non-coding RNAs are in blue and there is over 600 different mentions among the probes (large intergenic non-coding RNAs, lincRNAs make up most of the long ncRNAs). Even though they are less \textit{mentioned} in gene annotations (smaller bars) they do however cover 70\% of the annotated probes.
\marginnote{\small\color{blue}$\Lsh$ Two or more mentions (patterns) can be recognized in one gene}[0cm]
<<bar_ncrna>>=
colors <- c(rep("blue",2), rep("red",18))
read.table("./data/rna.patterns.annotated.array.txt", header = F) %>%
    mutate(percent = (V1/5 / (sum(V1)/5)) * 100) %>%
    slice(1:20) %>%
    ggplot(aes(x = reorder(V2, percent),
               y = V1,
               fill = colors)) +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    theme_minimal() +
    labs(x = "Amount of mentions from 75,524 microarray",
         y = "Top 20 mentioned RNA types")

@ 




\subsubsection{Regression analyses to quantify diagnosis connections}
\label{subsec:regression}
Logistic regression of binomial factoring between nodal/extranodal diagnosis and individuals labels for cell-of-origin classification and CNS relapse or systemic relapse.
Regression model summary with odds ratio with 95\% confidence interval to quantify how much nodal and extranodal diagnosis is associated with the cell-of-origin ABC or GCB nature in DLBCL individuals with CNS, systemic or no relapse.
<<tabulated_summary_logistic>>=
fit_summary_table <- function(features, dependent, df, method, execute = TRUE) {
    if ( execute == TRUE ) {
        if ( method == "glm" || method == "cox" ) {
            x <- df %>%
                finalfit(dependent, features)
        } else if ( execute == "glmer" ) {
            x <- df %>%
                finalfit(dependent, features, 
                         mixed, random_effect)
        }
        ## print latex table
        Hmisc::latex(x, file = "", booktabs = TRUE, title = "")
    } else {
        cat("LaTeX summary table printed\n")
    }
}


fit_summary_table(features= c("ABCScore", "ABClassify", "GROUP"),
                  dependent= c("Nodes"), 
                  df = metadata,
                  method = "glm",
                  execute = F)
@ 




\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-5pt}
\begin{tabular}{lllllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}&\multicolumn{1}{c}{OR (univariable)}&\multicolumn{1}{c}{OR (multivariable)}\tabularnewline
\midrule
4&ABCScore&ABC&34 (39.5)&58 (38.7)&-&-\tabularnewline
5&&GCB&36 (41.9)&67 (44.7)&1.09 (0.61-1.96, p=0.771)&0.44 (0.06-3.23, p=0.408)\tabularnewline
6&&U&16 (18.6)&25 (16.7)&0.92 (0.43-1.97, p=0.820)&0.96 (0.25-4.74, p=0.952)\tabularnewline
1&ABClassify&ABC&37 (43.0)&66 (44.0)&-&-\tabularnewline
2&&GCB&38 (44.2)&79 (52.7)&1.17 (0.67-2.04, p=0.591)&1.61 (0.24-10.98, p=0.615)\tabularnewline
3&&U&11 (12.8)&5 (3.3)&0.25 (0.08-0.76, p=0.018)&0.52 (0.07-2.97, p=0.473)\tabularnewline
7&GROUP&CNS DIAGNOSIS&7 (8.1)&4 (2.7)&-&-\tabularnewline
8&&CNS RELAPSE CHOP or EQUIVALENT&5 (5.8)&3 (2.0)&1.05 (0.15-7.08, p=0.960)&0.97 (0.13-6.76, p=0.979)\tabularnewline
9&&CNS RELAPSE RCHOP&20 (23.3)&19 (12.7)&1.66 (0.43-7.21, p=0.470)&1.71 (0.42-7.73, p=0.461)\tabularnewline
10&&NO RELAPSE&30 (34.9)&66 (44.0)&3.85 (1.08-15.64, p=0.042)&3.40 (0.91-14.2, p=0.074)\tabularnewline
11&&NORMAL ABC CONTROL&2 (2.3)&0 (0.0)&0.00 (NA-NA, p=0.995)&0.00 (NA-NA, p=0.995)\tabularnewline
12&&NORMAL GCB CONTROL&0 (0.0)&4 (2.7)&74.56 (0.00-NA, p=0.993)&79.25 (0.00-NA, p=0.993)\tabularnewline
13&&SYTEMIC RELAPSE NO CNS&10 (11.6)&54 (36.0)&9.45 (2.42-NA, p=0.002)&8.07 (1.98-NA, p=0.004)\tabularnewline
14&&TESTICULAR NO CNS RELAPSE&12 (14.0)&0 (0.0)&0.00 (0.00-NA, p=0.988)&0.00 (0.00-NA, p=0.988)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}



Mixed effects multilevel logistic regression model fit to find connections between individuals (CNS relapse, systemic, and no relapse) and cell-of-origin predictions (ABC, GCB likelihoods), while considering nodal and extranodal involvement in the relapse (diagnosed tissue sites with cancer invasion).
<<tabulated_summary_mixed>>=
mixed = c("GROUP")
random_effect = c("SITE")
fit_summary_table(features= c("Prediction", "GROUP"),
                  dependent= c("Nodes"),
                  df = metadata,
                  method = "glmer",
                  execute = F)

@ 


\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-5pt}
\begin{tabular}{lllllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}&\multicolumn{1}{c}{OR (univariable)}&\multicolumn{1}{c}{OR (multilevel)}\tabularnewline
\midrule
9&Prediction&ABC&34 (40.5)&58 (38.7)&-&-\tabularnewline
10&&GCB&36 (42.9)&67 (44.7)&1.09 (0.61-1.96, p=0.771)&-\tabularnewline
11&&U&14 (16.7)&25 (16.7)&1.05 (0.48-2.32, p=0.908)&-\tabularnewline
1&GROUP&CNS DIAGNOSIS&7 (8.1)&4 (2.7)&-&-\tabularnewline
2&&CNS RELAPSE CHOP or EQUIVALENT&5 (5.8)&3 (2.0)&1.05 (0.15-7.08, p=0.960)&0.38 (0.00-NA, p=0.989)\tabularnewline
3&&CNS RELAPSE RCHOP&20 (23.3)&19 (12.7)&1.66 (0.43-7.21, p=0.470)&0.49 (0.00-NA, p=0.988)\tabularnewline
4&&NO RELAPSE&30 (34.9)&66 (44.0)&3.85 (1.08-15.64, p=0.042)&1.70 (0.00-NA, p=0.989)\tabularnewline
5&&NORMAL ABC CONTROL&2 (2.3)&0 (0.0)&0.00 (NA, p=0.995)&0.00 (0.00-Inf, p=1.000)\tabularnewline
6&&NORMAL GCB CONTROL&0 (0.0)&4 (2.7)&NA (0.00-NA, p=0.993)&285412.87 (0.00-Inf, p=0.999)\tabularnewline
7&&SYTEMIC RELAPSE NO CNS&10 (11.6)&54 (36.0)&9.45 (2.42-42.22, p=0.002)&1.76 (0.00-NA, p=0.989)\tabularnewline
8&&TESTICULAR NO CNS RELAPSE&12 (14.0)&0 (0.0)&0.00 (0.00-NA, p=0.988)&0.00 (0.00-Inf, p=1.000)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}


\subsection{Featured data and groups of sample cases}
\label{subsec:groups}
Difference in cases being indexed based on their \textit{cell-of-origin} association subtypes using either of the following features: prediction, ABClassify, ABCScore.
<<cells_difference>>=
metadata %>%
    select(Prediction, ABClassify, ABCScore) %>%
    summary

@ 


Distribution of samples with different treatments.
<<treatments_bar>>=
metadata %>% 
    select(GROUP) %>%
    ggplot(aes(x = GROUP)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of lymphoma cases",
         x = "Patients diagnosis") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as a pie chart.
<<treatments_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$GROUP)))
pie(table(metadata$GROUP), col=palette.pies.adj)
@ 

Distribution of samples with different cells of origin subtypes.
<<subtypes_bar>>=
metadata %>% 
    select(Prediction) %>%
    ggplot(aes(x = Prediction)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of Cell-of-origin subtypes",
         x = "Patients Cell-of-origin classification") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as pie chart.
<<subtypes_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$Prediction)))
pie(table(metadata$Prediction), col=palette.pies.adj)
@ 

Distribution of samples with different lymphnodes and extranodal cancer metastasis.
<<nodes_bar>>=
par(mfrow=c(2,2))
metadata %>% 
    select(SITE) %>%
    ggplot(aes(x = SITE)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of Nodata origins",
         x = "Patients lymphnodes and extranodal tumor presence") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as a pie chart.
<<nodes_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$SITE)))
pie(table(metadata$SITE), col=palette.pies.adj)
@ 



\section{Differential expression of microarray Affymetrix data}
\label{sec:expression}
Genes have been fitted in a model that is based on an Empirical Bayes approach. Ranking of the genes determine if they are statistically significant. Bonferroni correction is used to control the false discovery rate (FDR). Moderated t-statistics, FDR, and fold change (log2) are implemented to reduce selection of false positives.

\begin{itemize}
\item \textbf{adjpval} is the adjusted P-value to control the FDR using Bonferroni correction. \textbf{Genes selected here based on their adjpval are also greater than or equal to the bstat threshold}.
\item \textbf{avgex} is the average expression the ordinary arithmetic average of the log2-expression values for the probe, across all arrays. \textbf{Genes selected here based on their avgex are also greater than or equal to the bstat threshold}.
\item \textbf{bstat} is the moderated t-statistics using an Empirical Bayes approach generating B-statistics scores. 
\end{itemize}

<<summary_expression>>=
expression <- read.table("data/summary.full.409794.txt", sep = "\t", header = T) %>%
    select(Design, Model, Bthreshold, adjPval, Category, Parameter, Transcripts) %>%
    filter(Category == "total")
summary(expression)
@ 

Number of transcripts when comparing B-statistics scores, which represent confidence in selecting each significantly expressed gene.
<<transcripts_bval>>=
aggregate( Transcripts ~ Bthreshold, data=expression, FUN=range)

@ 

Number of transcripts when samples are classed into groups, which are based on clinical data (e.g., cell-of-origin, CNS relapse, and nodal/extranodal tumor transmission).
<<transcripts_model>>=
aggregate( Transcripts ~ Model, data=expression, FUN=range)

@ 

Number of transcripts found when comparing different sample cases indexed based on their clinical data.
<<transcripts_design>>=
aggregate( Transcripts ~ Design, data=expression, FUN=range)
@ 


Number of genes that respond to treatment, cell subtypes, and nodal transmission.
\marginnote{\small\color{blue}$\Lsh$ Min adjusted p-value of 0.1}[0cm]
<<expression_bval,out.width='5in'>>=
expression %>% 
    ggplot(aes(
        x = Design,
        y = Transcripts,
        fill = factor(Bthreshold))) +
    theme_bw() +
    geom_bar(stat = "identity",
             position = "stack") +
    coord_flip() +
    facet_wrap( ~ Model,
              ncol = 1,
               scales = "free") + 
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "",
         y = "Differentially expressed genes after multiple linear model") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10))

@ 

\subsection{Cleaning and removing non-essential genes}
\label{subsec:subsetting}
\marginnote{\small\color{blue}$\Lsh$ $\sigma^2$ is the average of the squared differences from the $\mu$}[0cm]
Subsetting the data by reducing the number of gene profiles improves interpretation and reduces noise. It is well established that many machine learning models used for classification can be sensitive to high number of \textit{irrelevant} genes, others like support vector machines and random forests are less so \href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-319}{(Statnikov 2008)}.


Each array contains probes of 75,523 functional and non-functional RNAs. Either ncRNA, mRNA, and non annotated genes. More than 53.32\% of the probes are non-coding. For interpretation purpose, ncRNAs profiles were discarded before fitting the expressions. In addition, the variation from the mean of each transcript was assessed and the spread of expression were all used to discard top and bottom variants. Individual genes that vary widely from the mean of the array were removed thus reducing the spread of the expression across profiles. Transcripts with potential biased high expressions were thus flagged and discarded thus improving correlation of other transcripts.
Subsetting was done after normalization of all datasets, all arrays. This would reduce technical errors appearing significant when comparing arrays between each others. Data was transformed (standardization protocol) before calculating means and variances. This helps a better signal recovery from a large dataset with potential expression bias.
\marginnote{\small\color{blue}$\Lsh$ Each array correspond to a DLBCL case}[0cm]

\subsubsection{Variance optimization for each array}
\label{subsec:variance}
Full probe list accounting for 75,523 genes ({\color{red} red horizontal line}). The full line represents the variance after being adjusted by iteratively discarding top/low variant expression profiles. The dotted line represent the original variance before discarding genes.
\marginnote{\small\color{blue}$\Lsh$ The smaller the variance, the better}[0.5cm]

The graph below shows that by discarding highly variant expressions and selecting only the top 1613 genes for example, the mean variance of the whole array (0.27) is higher than a ranked subset of 10,811 (0.09). Ideally, the reduction of the data is on both, the mean variance and mean standard deviation of the whole array.
<<variance_w_ncrna_subsetting>>=
read.table("./data/summary.139102.adjusted.means.subsetting.txt", header = T) %>%
    select(dimension, meanVariance, adj.meanVariance) %>%
    gather("variance", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = dimension)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(variance))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 10)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    geom_hline(aes(yintercept = 75523), colour = "red") +
    labs(y = "Number of selected genes",
         x = "Variance") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 


Same plot description as above however we removed ncRNA which account for 53.32\% of the probes. The total number of transcripts is now 35,253 (46\%, {\color{red} red horizontal line}). The {\color{blue} blue horizontal line} represents the threshold that was selected for subsequent analysis.
\marginnote{\small\color{blue}$\Lsh$ 29,207 genes were selected for clustering and nets}[0cm]


By discarding 1198 transcripts from the 35,253 the top outliers with high variance are not included in the clustering process. More rare expression signals will get distinguished. Also, the size of the dataset was reduced to 29,207 by removing transcripts with little deviation from the mean of each array. The total number of transcripts by array was kept above 25k to increase the sizes of the clusters (modules and networks) in later analyses. For example, network analysis on 20k transcripts generated network sizes between 200 and 500. At 29k networks have a total size over 700 nodes.
<<variance_wo_ncrna_subsetting>>=
read.table("./data/summary.149317.adjusted.means.subsetting.txt", header = T) %>%
    select(dimension, meanVariance, adj.meanVariance) %>%
    gather("variance", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = dimension)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(variance))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    geom_hline(aes(yintercept = 35253), color = "red") +
    geom_hline(aes(yintercept = 29207), color = "blue") +
    labs(y = "Number of selected genes",
         x = "Variance") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


\subsubsection{Standard deviation optimization for each array }
\label{subsec:deviation}
The spread of the gene expression scores is dependent on their variance, their deviation from each array's mean (population mean). By removing potentially noisy expressions we are reducing the spread of the arrays numbers, hence improving recognition of rare gene regulations.
Below, the plot shows how the standard deviation, \textbf{spread} of the data is getting smaller the more we discard genes with high and low variance.
\marginnote{\small\color{blue}$\Lsh$ Best if small spread between 2 SDs}[0cm]

All array probes with all RNAs.
<<deviation_w_ncrna_subsetting>>=
read.table("./data/summary.139102.adjusted.means.subsetting.txt", header = T) %>%
    select(discarded, meanSD, adj.meanSD) %>%
    gather("sd", "count", 2:3) %>% 
    ggplot(aes(x = count,
               y = discarded)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(sd))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(y = "Number of discarded genes with high variance",
         x = "Standard deviation") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 

Without the ncRNAs. {\color{blue} Blue horizontal line} is the number of genes discarded when variance shrinking was used to eliminate biased genes.
<<deviation_wo_ncrna_subsetting>>=
read.table("./data/summary.149317.adjusted.means.subsetting.txt", header = T) %>%
    select(discarded, meanSD, adj.meanSD) %>%
    gather("sd", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = discarded)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(sd))) +
    geom_point() +
    geom_hline(aes(yintercept = 1175), colour = "blue") +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(y = "Number of discarded genes with high variance",
         x = "Standard deviation") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


\subsection{Distribution of p-values in pairwise comparisons}
\label{subsec:pvals}

Distribution of p-values in pairwise comparisons between individuals recognized as CNS relapse, systemic, and did not relapse.
<<pval_density_relapse>>=
pvals <- read.table("./data/summary.lmfit.fdrAdjpval.txt", header = TRUE, fill = TRUE)
pvals %>%
    filter(Contrast == "systemicRelapse") %>% 
    ggplot(aes(x = Pval,
               fill = Comparison)) +
    geom_density(position = "stack") +
    theme_minimal() +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 

Distribution of p-values in pairwise comparisons between individuals recognized as CNS relapse, systemic, and did not relapse.
<<pval_histograms_relapse>>=
pvals %>%
    filter(Contrast == "systemicRelapse") %>% 
    ggplot(aes(x = Pval,
               fill = Comparison)) +
    geom_histogram(binwidth = 10^-5,
                   col=I("white")) +
    theme_minimal() +
    facet_wrap( ~ Comparison,
               ncol = 1) +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 


Distribution of p-values in pairwise comparisons between individuals recognized with lymph nodes and extranodal implication.
<<pval_density_nodal>>=
pvals %>%
    filter(Contrast == c("systemicRelapseNodes")) %>% 
    ggplot(aes(x = Pval,
               fill = Comparison)) +
    geom_density(position = "stack") +
    theme_minimal() +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 

Distribution of p-values in pairwise comparisons between individuals recognized with lymph nodes and extranodal implication.
<<pval_histograms_nodal>>=
pvals %>%
    filter(Contrast == "systemicRelapseNodes") %>% 
    ggplot(aes(x = Pval,
               fill = Comparison)) +
    geom_histogram(binwidth = 10^-5) +
    theme_minimal() +
    facet_wrap( ~ Comparison,
               ncol = 2, scales = "free") +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 

Distribution of p-values in pairwise comparisons between individuals recognized with cell-of-origin based on ABC or GCB.
<<pval_density_coo>>=
pvals %>%
    filter(Contrast == c("systemicRelapseCOOprediction")) %>% 
    ggplot(aes(x = Pval,
               fill = Comparison)) +
    geom_density(position = "stack") +
    theme_minimal() +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Paired") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 

Distribution of p-values in pairwise comparisons between individuals recognized with cell-of-origin based on ABC or GCB.
<<pval_histograms_coo>>=
pvals %>%
    filter(Contrast == "systemicRelapseCOOprediction") %>% 
    ggplot(aes(x = Pval, 
               fill = Comparison)) +
    geom_histogram(binwidth = 10^-5) +
    theme_minimal() +
    facet_wrap( ~ Comparison,
               ncol = 2, scales = "free") +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Paired") +
    labs(x = "False discovery rate adjusted P-values",
         y = "Density")

@ 

Across all contrasts class comparison, the number of genes significantly expressed at FDR multi test corrections.
<<pval_density>>=
read.table("./data/summary.lmfit.bval.txt", header = TRUE, fill = TRUE) %>% 
    filter(Model == c("systemicRelapse","systemicRelapseNodes","systemicRelapseCOOprediction")) %>% 
    ggplot(aes(x = reorder(Design, Transcripts),
               y = Transcripts,
               fill = Model)) +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    theme_minimal() +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(y = "Number of differentially expressed genes at a maximum of 0.049 FDR adjusted p-value",
         x = "Model design for fitting an empirical Bayes")

@ 


\section{Clustering and network analyses}
\label{sec:networks}
The number of clusters and modules per networks are assigned by designing first a similarity matrix between differentially expressed gene for any two conditions (eg., relapse vs no relapse individual cases).
An adjacency matrix is then constructed by weighting the previously inferred measures.
The data is transformed to increase the correlation coefficient therefore improving detection of strong correlated patterns. (Example of the strength of data transformation and correlation, visit the following \href{https://blog.majestic.com/case-studies/correlation-data-transformations/}{online page}).\\

The final methods selected were best according to our output. Convergence and reproducibility of each trend in gene number per module or scale of module per network helped narrow down our selection criteria for which method to incorporate in our clustering technique. 
The best configuration involve a Pearson correlation at stringent thresholds. Hellinger expression data standardization was better than other methods in helping to estimate similarity between genes. 
The correlation power was set to 6 at an overall threshold of recall of 0.5 and a complete clustering distribution to improve estimating adjacency distribution.

  \marginnote{\small\color{blue}$\Lsh$Overfitting is a source of bias.}[0cm]
\begin{itemize}
\item \textbf{MaxEdgesPerGene}, maximum number of correlations per genes
\item \textbf{NbNodes}, number of genes found for each edge connection bracket
\item \textbf{Normalization}, method that focuses on creating complete clusters. We tested methods ranging from Complete clustering, Average, and Ward. \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html}{Each method is detailed here.} Only Complete clustering was retained. All other methods overfitted the data.
\item \textbf{Correlation}, finding ranges from linear to non-linear trends. We tested Pearson and Spearman correlation.
\item \textbf{Standardization}, data transformation method. We tested transformation by Hellinger, Standardize, Range, and Logarithmic scaling. \href{http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/decostand.html}{Each method is detailed here.}
\item \textbf{MaxGenePerModule}, how many genes assigned by cluster (module)
\item \textbf{SimilaritySize}, number of initial differentially expressed genes
\item \textbf{EdgeThreshold}, parameter to limit the weight of the edges
\item \textbf{CorrelationPower}, power transformation of the data
\end{itemize}
\marginnote{\small\color{blue}$\Lsh$Effect of correlation methods is seen on module content}[0cm]
<<networks_summary>>=
ns <- read.table("./data/networks.summary.437006.txt", header = T)
summary(ns)
@ 

\marginnote{\small\color{blue}$\Lsh$ Definitive graphs}[0cm]
Difference between methods used for network inference. Are we able to generate convergence of the output of all iterations across all methods?
After many trials the below two graphs (in this section) represent the number of networks, genes, clustered, and modules for the selected configuration (between normalization, clustering, and data transformation).
<<nodes_networks_summary_steps,out.width='5in'>>=
networks.comparison <- function(data = ns){
    data %>%
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_minimal() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"),
          axis.text.x = element_text(size = 8),
          axis.text.y = element_text(size = 8))
}

networks.comparison(data = ns)
@ 

Showing the number of modules per network and the number of genes per module. Each module contains differing number of nodes based on their correlation strength. Each cluster contains at least one module. Each network contains at least one cluster. One module can be assigned to nodes that belong to more than one cluster. The Lowess curves show if the trend in the data is linear or not. The wave around Lowess curves represents the level of confidence of the data points (the narrower the interval the better, less variability = more accuracy).
\marginnote{\small\color{blue}$\Lsh$Points=iterations. With less iterations comes high variability of the curve}[0cm]
<<nodes_modules_summary>>=
ms <- read.table("./data/modules.summary.437006.txt", header = TRUE)
modules.comparison <- function(data = ms){
data %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "none",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"),
          axis.text.x = element_text(size = 8),
          axis.text.y = element_text(size = 8)) +
    geom_smooth(method = 'loess', alpha = 1)
}

modules.comparison(data = ms)


@ 

\subsection{Network analysis for Spearman-related correlations (relaxed)}
\label{subsec:spearman}
\marginnote{\small\color{blue}$\Lsh$ Different iterations to test which normalization \& clustering are best}[0cm]
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed by shrinking the sample variance \href{http://www.statsci.org/smyth/pubs/ebayes.pdf}{Smyth 2004}. Limma implementation. 
\begin{itemize}
\item \textbf{Average Expression}: 5
\item \textbf{Adjusted P-value}: equal or less than 0.045
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 1.5
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_spearman>>=
ns <- read.table("./data/networks.summary.104859.txt", header = TRUE)
networks.comparison(ns)
@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_spearman>>=
ms <- read.table("./data/modules.summary.104859.txt", header = TRUE)
modules.comparison(ms)
@ 



\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_spearman>>=
ns <- read.table("./data/networks.summary.114018.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_spearman>>=
ms <- read.table("./data/modules.summary.114018.txt", header = TRUE)
modules.comparison(ms)
@ 


\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coospearmanstringent}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<coo_prediction_networks_summary_spearman>>=
ns <- read.table("./data/networks.summary.114017.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_spearman>>=
ms <- read.table("./data/modules.summary.114017.txt", header = TRUE)
modules.comparison(ms)
@ 



\subsection{Network analysis for Pearson-related correlations (relaxed)}
\label{subsec:pearson}
\marginnote{\small\color{blue}$\Lsh$With pearson, we can only raise the data to power 10. All are discarded after 10.}[0cm]
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\begin{itemize}
\item \textbf{Average Expression}: 5
\item \textbf{Adjusted P-value}: equal or less than 0.045
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 1.5
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_pearson>>=
ns <- read.table("./data/networks.summary.104862.txt", header = TRUE)
networks.comparison(ns)
@ 

\marginnote{\small\color{blue}$\Lsh$Since Lowess ranks by confidence, Log transformation seems the best, ie, low variability. For this, Log is removed from further tests.}[0cm]
Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_pearson>>=
ms <- read.table("./data/modules.summary.104862.txt", header = TRUE)
modules.comparison(ms)
@ 

\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapse}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_pearson>>=
ns <- read.table("./data/networks.summary.104863.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_pearson>>=
ms <- read.table("./data/modules.summary.104863.txt", header = TRUE)
modules.comparison(ms)    
@ 

\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coo}
Genetic networks from differentially expressed genes selected by comparing sample cases with cell of origin classification based on ABC or GCB subtypes.
<<coo_prediction_networks_summary_pearson>>=
ns <- read.table("./data/networks.summary.104864.txt", header = TRUE)
networks.comparison(ns)
@ 



Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_pearson>>=
ms <- read.table("./data/modules.summary.104864.txt", header = TRUE)
modules.comparison(ms)
@ 





\subsection{Network analysis for Spearman-related correlations (stringent)}
\label{subsec:spearman}
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\marginnote{\small\color{blue}$\Lsh$Same analysis with more stringent parameters}[0cm]
\begin{itemize}
\item \textbf{Average Expression}: 10
\item \textbf{Adjusted P-value}: equal or less than 0.030
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 2
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}
Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_spearman_stringent>>=
ns <- read.table("./data/networks.summary.119759.txt", header = TRUE)
networks.comparison(ns)
@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_spearman_stringent>>=
ms <- read.table("./data/modules.summary.119759.txt", header = TRUE)
modules.comparison(ms)
@ 



\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_spearman_stringent>>=
ns <- read.table("./data/networks.summary.119760.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_spearman_stringent>>=
ms <- read.table("./data/modules.summary.119760.txt", header = TRUE)
modules.comparison(ms)
@ 



\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<coo_prediction_networks_summary_spearman_stringent>>=
ns <- read.table("./data/networks.summary.119758.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_spearman_stringent>>=
ms <- read.table("./data/modules.summary.119758.txt", header = TRUE)
modules.comparison(ms)
@ 



\subsection{Network analysis for Pearson-related correlations (stringent)}
\label{subsec:pearson}
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\marginnote{\small\color{blue}$\Lsh$Same analysis with more stringent parameters}[0cm]
\begin{itemize}
\item \textbf{Average Expression}: 10
\item \textbf{Adjusted P-value}: equal or less than 0.030
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 2
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_pearson_stringent>>=
ns <- read.table("./data/networks.summary.119755.txt", header = TRUE)
networks.comparison(ns)
@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_pearson_stringent>>=
ms <- read.table("./data/modules.summary.119755.txt", header = TRUE)
modules.comparison(ms)
@ 

\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapse}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_pearson_stringent>>=
ns <- read.table("./data/networks.summary.119754.txt", header = TRUE)
networks.comparison(ns)
@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_pearson_stringent>>=
ms <- read.table("./data/modules.summary.119754.txt", header = TRUE)
modules.comparison(ms)
@ 

\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coo}
Genetic networks from differentially expressed genes selected by comparing sample cases with cell of origin classification based on ABC or GCB subtypes.
<<coo_prediction_networks_summary_pearson_stringent>>=
ns <- read.table("./data/networks.summary.119757.txt", header = TRUE)
networks.comparison(ns)
@ 



Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_pearson_stringent>>=
ms <- read.table("./data/modules.summary.119757.txt", header = TRUE)
modules.comparison(ms)
@ 



\section{Machine Learning}
\label{sec:machinelearning}
Machine learning models were used for classification of cases into systemic relapse of DLBCL, CNS relapse or no relapse. Data are gene expression from Affymetrix arrays of 240 individuals with a form of DLBCL. Subsets of the whole number of microarray probes will be used for classification.

\subsection{Regularization}
\label{subsec:regularization}
Least absolute shrinkage and selection operator (LASSO) was used for dimension reduction. Gene expression profiles were extracted from networks with significant connectivity. Subset selection using lasso, penalizes genes based on coefficient estimates, to increase accuracy of classification.
Briefly, cases are assigned to either diagnosis category, systemic relapse (SYST), CNS relapse (CNS), and no relapse (NOREL). During each iteration, a prediction is made to assign a category. Then a probability is calculated for having an accuracy performance for that iteration. A single iteration has a different random seed, which generates a different set of lambda coefficients for adjusting the lasso penalty. The best lambda across a grid of coefficients with the best accuracy classification is then selected based on accuracy. Adjusting the lambda score also adjusts the subset of genes used for the classification. For one best lambda there is one subset of significantly expressed genes and each gene has a different probability. For one best lambda there is one mean probability registered for that subset of genes.
\marginnote{\small\color{blue}$\Lsh$If a subset has 50 genes, the reported probabilities are the mean of each gene individual probability to predict all individual cases}[0cm]

\subsubsection{Uncertainty estimation for selected genes from expression networks}
\label{subsec:uncertainty}
The chart below shows how many iterations (dots) were executed for each sample group before selecting a subset of genes through regularization.

The probabilities are the fitted values of either a multinomial or binomial model at the best lambda ($\lambda$), shrinking parameter determined by tuning and cross-validation resampling. When predictions were made with lasso, the least squares were penalized. Lasso zero out coefficient estimates thus reducing the data. The fitted values are compared to the outcome to follow the proportion of variance "explained" by the model and the proportion of variance "not explained".\\

Peaks in density represents variance fitted at best $\lambda$ between sample groups. Probabilities are compared to the residuals of the data, the outcome is the fitted values. As long as the peaks differ between groups, then the prediction is possible between samples. There is an overlay between CNS and SYST groups, which indicates the presence of some bias in differentiating between them.
<<density_probabilities_lambda>>=
read.table("./data/logSummary.lambda.iterations30.multinomial.probabilities.txt", 
           row.names = 1, header = T) %>%
    ggplot(aes(x = probabilityScore,
               fill = class)) +
    geom_density() +
    theme_minimal() +
    facet_grid(class ~ .) +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Fitted values of a subset of genes",
         y = "Density (fitted probabilities with lambda = 1)")
@ 


Density plot summarizing the distribution of how many times the CNS/NOREL/SYST sample classes were correctly predicted against other classes using the list of genes that supposedly represent individuals with each type of prognosis.
<<density_probabilities>>=
read.table("./data/logSummary.lambda.iterations30.multinomial.densities.txt", 
           row.names = 1, header = T) %>% 
    filter(classes == c("CNS", "SYST", "NOREL")) %>%
    ggplot(aes(x = probabilities,
               fill = classes)) +
    geom_density() +
    theme_minimal() +
    facet_wrap( ~ genes,
               ncol = 1,
               scales = "free") +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Density (fitted probabilities with lambda = 1)")
@ 


Plot showing the accuracy of assigning an individual to its correct class (or diagnosis) based on lambda calculation for lasso regularization. Each facet represents an accuracy for multiple iterations with a specific number of genes.
<<boxplot_accuracies_lambda,out.width='6in',out.height='2in'>>=
df <- read.table("./data/logSummary.lambda.iterations30.multinomial.accuracies.txt", 
                 row.names = 1, header = T)
mir <- min(df$regNgenes)
mar <- max(df$regNgenes)
q1 <- floor((mir+mar)/2.5)
q2 <- floor((mir+mar)/1.75)
df$grouped <- cut(df$regNgenes, c(0, q1, q2, mar))
levels(df$grouped) <- c(paste0(0,"-",q1), 
                        paste0(q1+1,"-",q2), 
                        paste0(q2+1,"-",mar))
df %>%
    ggplot(aes(x = group,
               y = accuracy,
               fill = group)) +
    geom_violin(trim = FALSE) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    labs(x = "Different diagnosis for patients with DLBCL",
         y = "Accuracy scores for multiple iterations of classification (95% CI)") +
##    theme(legend.position = "top") +
    facet_wrap( ~ grouped,
               ncol = 3,
               scales = "free")


@ 



\subsection{Selected machine and deep learning models}
\label{subsec:models}
Selection of learners was based on historical efficiency of such algorithms. Also, the training of classifiers starts from simple logistic regression, naive bayes, nearest neighbors, going to more flexible models, such as trees and deep neural nets that require more hyperparameter tuning. This strategy lets assess with less bias the overfitting issues that may arise.

\begin{table}[h]
  % \captionsetup{format=plain,justification=centerlast}
  \caption{\bf Machine learning models}
  \renewcommand{\arraystretch}{0.8}
   \small\addtolength{\tabcolsep}{-3.5pt}
  \begin{tabular}{l p{6.2cm} l p{4.5cm} l}
    \toprule
    
    \# & Classifiers trained & R package$^*$ & Parameters$^{\dagger}$ tuned & Abbreviation \\
    
    \midrule

    1 & Naive bayes & \href{https://cran.r-project.org/web/packages/naivebayes/index.html}{naivebayes} & laplace, usekernel, adjust & naive\_bayes \\
    2 & Weighted k-Nearest Neighbors & \href{https://cran.r-project.org/web/packages/kknn/index.html}{kknn} & kmax, distance, kernel & kknn \\
    3 & Penalized multinomial regression & \href{https://cran.r-project.org/web/packages/nnet/index.html}{nnet} & decay & multinom \\
    4 & Random forest & \href{https://cran.r-project.org/web/packages/randomForest/index.html}{randomForest} & mtry & rf \\
    5 & Regularized random forest & \href{https://cran.r-project.org/web/packages/RRF/index.html}{RRF} & mtry, coefReg, coefImp & RRF \\
    6 & Linear discriminant analysis (LDA) & \href{https://cran.r-project.org/web/packages/MASS/index.html}{MASS} & dimen & lda2 \\
    7 & Multilayer perceptron network by stochastic gradient descent & \href{https://cran.r-project.org/web/packages/FCNN4R/index.html}{FCNN4R} & size, l2reg, lambda, learn\_rate, momentum, gamma, minibatchsz, repeats & mlpSGD \\
    8 & Flexible discriminant analysis (FDA) & \href{https://cran.r-project.org/web/packages/mda/index.html}{mda} & degree, nprune & fda \\
    9 & Bagged FDA & \href{https://cran.r-project.org/web/packages/mda/index.html}{mda} & degree, nprune & bagFDA \\
    10 & Bagged FDA using gCV pruning & \href{https://cran.r-project.org/web/packages/earth/index.html}{earth} & degree & bagFDAGCV \\
    11 & Penalized discriminant analysis & \href{https://cran.r-project.org/web/packages/mda/index.html}{mda} & lambda & pda \\
    12 & Partial least squares & \href{https://cran.r-project.org/web/packages/pls/index.html}{pls} & ncomp & kernelpls \\
    13 & Support vector machines (SVM) with linear kernel & \href{https://cran.r-project.org/web/packages/kernlab/index.html}{kernlab} & C & svmLinear \\
    14 & L2 regularized SVM (dual) with linear kernel & \href{https://cran.r-project.org/web/packages/LiblineaR/}{LiblineaR} & cost, loss & svmLinear3 \\
    15 & SVM with polynomial kernel & \href{https://cran.r-project.org/web/packages/kernlab/index.html}{kernlab} & degree, scale, C & svmPoly \\
    16 & SVM with radial basis function kernel & \href{https://cran.r-project.org/web/packages/kernlab/index.html}{kernlab} & sigma, C & svmRadialSigma \\
    17 & Neural network (NN) & \href{https://cran.r-project.org/web/packages/nnet/index.html}{nnet} & size, decay & nnet \\
    18 & NN with feature extraction & \href{https://cran.r-project.org/web/packages/nnet/index.html}{nnet} & size, decay & pcaNNet \\    
    19 & Monotone multi-layer perceptron NN & \href{https://cran.r-project.org/web/packages/monmlp/}{monmlp} & hidden1, n.ensemble & monmlp \\
    20 & Stacked autoencoder deep NN & \href{https://cran.r-project.org/web/packages/deepnet/}{deepnet} & layer1, layer2, layer3, hidden\_dropout, visible\_dropout & dnn \\
    21 & Stochastic gradient boosting & \href{https://cran.r-project.org/web/packages/gbm/}{gbm} & n.trees, interaction.depth, shrinkage, n.minobsinnode & gbm \\
%%    21 & Deep NN & \href{https://mxnet.incubator.apache.org/}{mxnet} & layer1, layer2, layer3, learning.rate, momentum, dropout, activation & mxnet \\    
%%    23 & Regularized logistic regression & \href{https://cran.r-project.org/web/packages/LiblineaR}{LiblineaR} & cost, loss, epsilon & regLogistic \\    
%%    7 & Localized LDA & \href{https://cran.r-project.org/web/packages/klaR/index.html}{klaR} & k & loclda \\
%%    21 & Boosted logistic regression & \href{https://cran.r-project.org/web/packages/caTools/}{caTools} & nlter & LogitBoost \\
    

    \bottomrule
  \end{tabular}
  \vspace{-10pt}
  \caption*{
    $^*$ The version of each package is shared under section \ref{subsec:version}.
    Links are forwarded to the CRAN page (except those imported from \href{https://www.tensorflow.org/}{Tensorflow} and \href{https://www.h2o.ai/}{H2O}) of each package for assessment of version, vignettes, advanced functionality, and description. 
    $^{\dagger}$Parameters are crucial to optimize for accuracy (95\% CI). Similar models have different parameters. 
%    The mxnet package has an activation function, read more \href{https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks}{here}.
    Multi-layered neural networks are used for deep learning. In some instances, only the layer 1 is used. For such instances the classifier is considered a neural network.
  }
  \label{tab:models}
\end{table}


\subsection{Available and tuned hyperparameters for each model}
\label{subsec:tuned}

\begin{table}
  \renewcommand{\arraystretch}{1}
 \small\addtolength{\tabcolsep}{-4pt}
  \caption{\bf Hyperparameters for each classifier.}
  \begin{tabular}{ p{6.5cm} | l c c c }
    \toprule
    Classifier trained & Hyperparameter & Scenario A$^*$ & Scenario B$^{**}$ & Scenario C$^{***}$ \\
    \midrule
    \multirow{3}{*}{Naive bayes} & laplace & & & \\
                       & usekernel & & & \\
                       & adjust & & & \\ \cline{2-5}
    \multirow{3}{*}{Weighted k-Nearest Neighbors} & kmax & & & \\
                       & distance & & & \\
                       & kernel & & & \\ \cline{2-5}
    \multirow{1}{*}{Penalized multinomial regression} & decay & & & \\
    \multirow{1}{*}{Random forest} & mtry & & & \\ \cline{2-5}
    \multirow{3}{*}{Regularized random forest} & mtry & & & \\
                       & coefReg & & & \\
                       & coefImp & & & \\ \cline{2-5}
    \multirow{1}{*}{Linear discriminant analysis (LDA)} & dimen & & & \\ \cline{2-5}
    \multirow{1}{*}{Localized LDA} & k & & & \\ \cline{2-5}
    \multirow{2}{*}{Flexible discriminant analysis (FDA)} & degree & & & \\
                       & nprune & & & \\ \cline{2-5}
    \multirow{2}{*}{Bagged FDA} & degree & & & \\
                       & nprune & & & \\ \cline{2-5}
    \multirow{1}{*}{Bagged FDA using gCV pruning} & degree & & & \\ \cline{2-5}
    \multirow{1}{*}{Penalized discriminant analysis} & lambda & & & \\ \cline{2-5}
    \multirow{1}{*}{Partial least squares} & ncomp & & & \\ \cline{2-5}
    \multirow{1}{*}{Support vector machines (SVM) with linear kernel} & C & 0.1 & & \\ \cline{2-5}
    \multirow{2}{*}{L2 regularized SVM (dual) with linear kernel} & cost & & & \\
                       & loss & & & \\ \cline{2-5}
    \multirow{3}{*}{SVM with polynomial kernel} & degree & & & \\
                       & scale & & & \\
                       & C & & & \\ \cline{2-5}
    \multirow{2}{*}{SVM with radial basis function kernel} & sigma & & & \\
                       & C & & & \\ \cline{2-5}
    \multirow{2}{*}{Neural network (NN)} & size & & & \\
                       & decay & & & \\ \cline{2-5}
    \multirow{2}{*}{NN with feature extraction} & size & & & \\
                       & decay & & & \\ \cline{2-5}
    \multirow{2}{*}{Monotone multi-layer perceptron NN} & hidden1 & & & \\
                       & n.ensemble & & & \\ \cline{2-5}
    %% \multirow{7}{*}{Deep NN} & layer1 & & & \\
    %%                    & layer2 & & & \\
    %%                    & layer3 & & & \\
    %%                    & learning.rate & & & \\
    %%                    & momentum & & & \\
    %%                    & dropout & & & \\
    %%                    & activation & & & \\ \cline{2-5}
    \multirow{5}{*}{Stacked autoencoder deep NN} & layer1 & & & \\
                       & layer2 & & & \\
                       & layer3 & & & \\
                       & hidden\_dropout & & & \\
                       & visible\_dropout & & & \\ \cline{2-5}
    %% \multirow{3}{*}{Regularized logistic regression} & cost & & & \\
    %%                    & loss & & & \\
    %%                    & epsilon & & & \\ \cline{2-5}
    \multirow{1}{*}{Boosted logistic regression} & nlter & & & \\ \cline{2-5}
    \multirow{4}{*}{Stochastic gradient boosting} & n.trees & & & \\
                       & interaction.depth & & & \\
                       & shrinkage & & & \\
                       & n.minobsinnode & & & \\ \cline{2-5}
    \multirow{8}{*}{Multilayer perceptron network} & size & & & \\
                       & l2reg & & & \\
                       & lambda & & & \\
                       & learn\_rate & & & \\
                       & momentum & & & \\
    by stochastic gradient descent & gamma & & & \\
                       & minibatchsz & & & \\
                       & repeats & & & \\
    \bottomrule
  \end{tabular}
  \vspace{-10pt}
  \caption*{ 
    $^{*}$Comparing samples with individuals grouped by either having a central nervous system relapse (CNS), systemic relapse (SYST), no relapse (NOREL) or controls. $^{**}$Comparing samples with individuals grouped by either having an activated B-cell (ABC) or germinal center B-cell (GCB) diagnosis. $^{***}$Comparing samples with individuals grouped by either having an tumor occurrence in lymph nodes (LN) in contrast to extra-nodal (EN) presence. The tuning parameters were iterated across a random selection grid for best tuning. Grid configurations are found \href{https://github.com/neocruiser/pipelines/blob/master/r/classification.R}{on Github}.}
  \label{tab:hyperparameters}
\end{table}






\subsection{Machine learning performance benchmarks}
\label{subsec:benchmarks}
Please follow up on performance metrics for classification problem by reading \href{http://rali.iro.umontreal.ca/rali/sites/default/files/publis/SokolovaLapalme-JIPM09.pdf}{Sokolova 2009}.
\marginnote{\small\color{blue}$\Lsh$ \href{https://scaryscientist.blogspot.com/2016/03/confusion-matrix.html}{Link} to metrics definitions}[0cm]
\begin{itemize}
\item \textbf{Sensitivity}, is how many true cases are correctly classified to their expected class. Or \textbf{recall}, is the fraction of events where we correctly declared $i$ form all cases where the true of state of the world is $i$. $TP / (TP + FN)$
\item \textbf{Specificity}, is how many wrong cases are correctly classified elsewhere. $TN / (TN + FP)$
\item \textbf{Precision}, is the fraction of events where we correctly declared $i$ out of all instances where the algorithm declared $i$. $TP / (TP + FP)$
\item \textbf{Accuracy}, is an overall measure that assesses the predictive model by comparing predicted classes to observed expected classes. Scores can also be shown as the area under the receiver operator curve (AUROC, 95\% CI). $(TN + TP) / (TP + TN + FP + FN)$
  \end{itemize}

\subsubsection{Creating the baseline of models performance}
\label{subsec:baseline}
\marginnote{\small\color{blue}$\Lsh$ Precision and recall are best for multi class learning}[0cm]
Machine learning models were trained only without tuning for hyperparameter optimization. Metrics generated show the raw performance of each model.\\

For this type of nominal data, classification models (not regression) are used, see Section /ref{subsec:models}. The performance metrics for this type of models are an accuracy score and kappa, which takes into account the possibility of the agreement occurring by chance (the kappa score however reflects the adequate agreement). Standard error ({\color{red}SE in red}) bars for the kappa significance per model reproducible across 10 cross-validation each repeated 5 times. Minimum and maximum accuracy thresholds are held at 95\% confidence intervals.\\
\marginnote{\small\color{blue}$\Lsh$ Kappa is Cohen’s (unweighted) Kappa statistic averaged across the resampling results}[0cm]


Load standard error and deviation equations.
<<summary_function>>=
summary_SE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {

    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }
    datac <- ddply(data, groupvars, .drop=.drop,
                   .fun= function(xx, col, na.rm) {
                       c( N    = length2(xx[,col], na.rm=na.rm),
                         mean = mean   (xx[,col], na.rm=na.rm),
                         sd   = sd     (xx[,col], na.rm=na.rm)
                         )
                   },
                   measurevar,
                   na.rm
                   )
    datac <- rename(datac, c("mean"=measurevar))
    # Calculate standard error of the mean
    datac$se <- datac$sd / sqrt(datac$N) 
    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval:
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult
    return(datac)
}

@ 

Metrics for classification performance without tuning for hyperparameter optimization. Quick comparison of statistical learning on the DLBCL data.
\marginnote{\small\color{blue}$\Lsh$ Accuracy, is the true prediction rate averaged over cross-validation iterations}[0cm]
<<bar_performance_ml_metrics,out.width='3in'>>=
accuracy.pre <- read.table("./data/reports.437017/log.Accuracy.performance1.multianalysis.seed5437259.437017.txt", header = TRUE)
kappa <- read.table("./data/reports.437017/log.Kappa.performance1.multianalysis.seed5437259.437017.txt", header = TRUE)

accuracy.se <- summary_SE(accuracy.pre, measurevar = "Mean", groupvars = "model")
kappa.se <- summary_SE(kappa, measurevar = "Mean", groupvars = "model") %>%
    arrange(Mean) %>%
    mutate(model = factor(model, unique(model)))

accuracy.se %>%  
    arrange(Mean) %>% 
    mutate(model = factor(model, unique(model))) %>%
    ggplot(aes(x = model,
               y = Mean)) +
    geom_bar(position="dodge",
             stat="identity",
             fill = "steelblue") +
    geom_errorbar(data = accuracy.se,
                  aes(ymin=Mean-se, 
                      ymax=Mean+se),
                  width=.3,
                  position=position_dodge(.9)) +
    geom_line(data = kappa.se,
              aes(x = as.integer(model),
                  y = Mean),
              color = "red") +
    geom_point(data = kappa.se,
               size=2, shape=21, fill="red") +
    geom_errorbar(data = kappa.se,
                  aes(ymin=Mean-se, 
                      ymax=Mean+se),
                  width=.25,
                  position=position_dodge(.9),
                  color = "white") +
    theme_minimal() +
    ylab("Mean of accuracy across 10 CV resampled 10 times/iteration (10 iterations)") +
    xlab("Machine Learning models iterated for 10 rounds") +
    theme(legend.position = "top") + 
    guides(fill=guide_legend(title="Number of parameters per model")) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))
@ 

Kappa (vertical axis) and accuracy (horizontal axis) calculated from the performance tests of machine learning models. The higher kappa is the stronger agreement for a prediction and classification. Although, this chart shows little correlation between prediction accuracy and outcome of each model, its important to highlight the number of parameters tune for each classifier. Because, based on a recent paper from Google in Nature, \href{https://www.nature.com/articles/s41746-018-0029-1}{Rajkomar 2018}, deep learning models with many layers and hyperparameters perform well enough as a regularized logistic regression model (Supplementary text). In the paper however, little was mentioned about this discrepancy in the published results. Lastly, it remains important to address the value of the parameters that are manipulated and the amount of time spent training the model based on the tuning process.
<<scatterplot_performance_ml_metrics,out.width='5in'>>=
## get single instance label names
model.names <- data.frame(accuracy.pre, kappa) %>%
    select(model, iteration, Mean, Mean.1) %>%
    filter(iteration == 1)

data.frame(accuracy.pre, kappa) %>% 
    ggplot(aes(x = Mean,
               y = Mean.1,
               color = model,
               label = model)) + 
    geom_point(aes(size=parameters, fill = model), shape=21) +
    geom_rug(aes(color = as.character(model)), 
             sides = "tr",
             show.legend = F) +
    geom_text_repel(data = subset(model.names, Mean >= .6),
                    nudge_x = .04,
                    nudge_y = -.03,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
    geom_text_repel(data = subset(model.names, Mean < .6),
                    nudge_x = -.1,
                    force = 8,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
    theme_minimal() +
    ylab("Mean of Kappa with adequate probability agreement") +
    xlab("Mean of accuracy with overall perdiction certainty") +
    theme(legend.position = "none")
@ 

Mean accuracy (95\% CI) registered for machine learning fitting for all classification groups. Iterations for reproducibility were executed 10 times.
<<boxplot_maximum_performance_ml_metrics,out.width='4in'>>=
accuracy.pre %>% 
    ggplot(aes(x = reorder(model, Mean),
               y = Mean,
               fill = as.character(parameters))) +
    geom_boxplot() +
    geom_jitter(shape=16, position=position_jitter(0.2), cex = 1.5) +
    coord_flip() +
    scale_fill_brewer(palette = "Dark2") +
    theme_minimal() +
    ylab("Mean accuracy across 10 CV resampled 10 times/iteration (Total 10 iterations)") +
    xlab("") +
    theme(legend.position = "top") + 
    guides(fill=guide_legend(title="Number of parameters per model"))
@ 


\subsubsection{Models performance with hyperparameter tuning}
\label{subsec:tuning}
Compared to the baseline, the parameters available for each learner should increase its performance at predicting each expected outcome. Tuning these hyperparameters will leverage the results with increased accuracy.\\

Mean accuracy (95\% CI) registered for machine learning fitting for all classification groups. Iterations for reproducibility were executed 10 times.
<<boxplot_TunedMaximum_performance_ml_metrics,out.width='4in'>>=
accuracy.pst <- read.table("./data/reports.437017/log.Accuracy.performance2.hyperTuning.seed5437259.437017.txt", header = TRUE)
accuracy.pst %>% 
    arrange(Mean) %>%
    mutate(model = factor(model, unique(model))) %>%
    ggplot(aes(x = model,
               y = Mean)) +
    geom_point(size = 3, shape = 21, fill = "red") +
    geom_line(aes(x = as.integer(model),
                  y = Mean)) +
    scale_fill_brewer(palette = "Dark2") +
    theme_minimal() +
    ylab("Mean accuracy across 10 CV resampled 10 times/iteration (Total 10 iterations)") +
    xlab("Machine Learning models iterated 10 rounds") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))
@ 


Showing the mean accuracy of each model across its maximum predictive performance.
<<scatterplot_Tunedperformance_ml_metrics,out.width='5in'>>=
accuracy.pst %>%
    ggplot(aes(x = Mean,
               y = Max.,
               fill = model,
               label = as.factor(model))) + 
    geom_point(aes(size=parameters), shape=21) +
    geom_label_repel(data = subset(accuracy.pst, Mean >= .65),
                     nudge_x = -.1,
                    force = 10,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
    theme_minimal() +
    ylab("Max accuracy with adequate probability agreement") +
    xlab("Mean accuracy with overall perdiction certainty") +
    theme(legend.position = "none")
@ 


Comparing the performance of each model during baseline testing versus optimization, both during the training process.
<<line_accuracy_baseline_optimized>>=
pre.tune <- accuracy.se %>% 
    select(model, Mean)
post.tune <- accuracy.pst %>%
    select(model, Mean)

full_join(pre.tune, post.tune, by = "model") %>% 
    gather("condition", "Mean", 2:3) %>%
    arrange(Mean) %>%
    mutate(model = factor(model, post.tune$model)) %>%
    ggplot(aes(x = reorder(model, Mean),
           y = Mean,
           fill = condition)) +
    geom_point(shape = 21, size = 2) +
    theme_minimal() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8),
          legend.position = "none")

@ 


\subsubsection{Genomic representation of selected genes}
\label{subsec:genome}
Distribution of all the genes that were selected after differential expression and network analysis.
<<distribution_chromosome_networks>>=
read.table("./data/log.gene.names_allnetworks.txt", header = T) %>% 
    mutate(order = gsub("chr", "", chromosome)) %>% 
    mutate(order = gsub("X", "24", order)) %>% 
    mutate(order = gsub("Y", "25", order)) %>%
    arrange(as.numeric(order)) %>% 
    ggplot(aes(x = reorder(chromosome, as.numeric(order)))) +
    geom_histogram(stat = "count", fill = "firebrick") +
    theme_minimal() +
    labs(x = "Chromosomes",
         y = "Number of genes per chromosome") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@ 


Distribution of the genes with preferential transcriptional characteristics to predict individuals who are at risk or not of CNS relapse after diagnosis and DLBCL treatment.
<<distribution_chromosome_bestLambda>>=
read.table("./data/log.gene.names_bestLambda.txt", header = T) %>%
    mutate(order = gsub("chr", "", chromosome)) %>% 
    mutate(order = gsub("X", "24", order)) %>% 
    mutate(order = gsub("Y", "25", order)) %>%
    arrange(as.numeric(order)) %>%
    ggplot(aes(x = reorder(chromosome, as.numeric(order)))) +
    geom_histogram(stat = "count", fill = "steelblue") +
    theme_minimal() +
    labs(x = "Chromosomes",
         y = "Number of genes per chromosome") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@ 


\subsubsection{Prediction accuracy of each classifier at optimal parameters}
\label{subsec:optimal}
Final report of the actual accuracy (95\% CI) for each machine learning model from comparing predicted values and expected outcomes.\\
\marginnote{\small\color{blue}$\Lsh$ Data are retrieved from Confusion Matrix}[0cm]

How long (seconds) a statistical learner requires to optimize the hyperparameters and gets the highest significant accuracy on expected data.
<<bar_duration_tuned_performance>>=
df <- read.table("./data/reports.437017/log.performance3.full.hyperTuning.seed5437259.437017.txt", header=T)
df$group <- gsub("[0-9]", "", df$group)

df %>% 
    arrange(durationMinutes) %>% 
    mutate(model = factor(model, unique(model))) %>% 
    ggplot(aes(x = model,
               y = durationMinutes)) +
    geom_point(stat = "identity",
               size=3, shape=21,
               fill = "red") +
    geom_line(aes(x = as.integer(model))) +
    theme_minimal() +
    xlab("Machine learners") +
    ylab("Time (minutes) for tuning and optimizing precision/recall") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))
@ 


Showing the mean accuracy of each model in contrast to their specificity for predicting individuals classes.
<<scatterplot_specificity_tuned_accuracymean>>=
specificity.mean <- df %>% 
    select(model, Specificity) %>%
    summary_SE(measurevar = "Specificity", groupvars = "model") %>%
    select(model, Specificity)

accuracy.mean <- accuracy.pst %>% 
    select(model, Mean)

p <- full_join(specificity.mean, accuracy.mean, by = "model") %>% 
        ggplot(aes(x = Mean,
               y = Specificity,
               fill = as.factor(model))) +
    geom_point(shape=21, size = 3) +
    geom_text(aes(x = Mean,
                  y = Specificity,
                  label = model,
                  hjust = 1.3,
                  vjust = 1), size = 3) + 
    theme_minimal() +
    ylab("Max accuracy with adequate probability agreement") +
    xlab("Mean accuracy with overall perdiction certainty") +
    theme(legend.position = "none")

    ggMarginal(p, type = "histogram", fill="transparent")

@ 


How is time training a model deliver on the significance of its accuracy? The p-value evaluates whether the overall accuracy rate is greater than the rate of the largest class. Proportions between classes (if one group of samples is larger than an other) is also considered in the hypothesis testing.
\marginnote{\small\color{blue}$\Lsh$ \href{https://topepo.github.io/caret/measuring-performance.html}{Link} documentation Section 17.2}[0cm]
<<scatterplot_duration_tuned_performance>>=
unique.acc <- df %>% 
    select(model, accuracyPval, durationMinutes) %>%
    unique()

df %>% 
    ggplot(aes(y = accuracyPval,
               x= durationMinutes,
               fill = as.character(model),
               label = as.factor(model))) +
    geom_point(size = 4,
               shape = 21) +
    geom_label_repel(data = subset(unique.acc, accuracyPval <= .01),
                    nudge_y = -1,
                    nudge_x = 250,
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
    theme_minimal() +
    xlab("Time (minutes) for tuning and optimizing precision/recall") +
    ylab("P-value between correct prediction and no-information classification") +
    theme(legend.position = "none")    
@ 

Precision versus recall across all sample groups for a multi-class classification.
\marginnote{\small\color{blue}$\Lsh$True/False Positives/Negatives}[0cm]
<<scatterplot_tuned_precision_recall_performance,out.width='5in'>>=
prec.rec <- df %>% 
    select(group, model, Precision, Recall)

df %>% 
    ggplot(aes(x = Precision,
               y = Recall,
               fill = model,
               label = as.factor(model),
               na.rm = T)) +
    geom_point(aes(shape = group, color = model), 
               size = 2) +
    geom_label_repel(data = subset(prec.rec, Recall >= .75),
                    nudge_y = -1,
                    nudge_x = -.1,
                    force = 1,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    facet_wrap(~ group, ncol = 1) +
    theme_minimal() +
    xlab("Precision of how many correct classes were called") +
    ylab("Recall/Sensitivity") +
    theme(legend.position = "none")               
@ 


Specificity and sensitivity across all sample groups.
<<scatterplot_tuned_sepecificity_Sensitivity_performance>>=
spec.sens <- df %>% 
    select(group, model, Sensitivity, Specificity)

df %>%
    ggplot(aes(x = Sensitivity,
               y = Specificity,
               fill = model,
               label = as.factor(model))) +
    geom_point(aes(shape = group,
                   color = model),
               size = 2) +
    geom_label_repel(data = subset(spec.sens, Specificity >= .7 & Sensitivity >= .7),
                    nudge_y = -1,
                    nudge_x = .1,
                    force = 1,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    facet_wrap(~ group, ncol = 1) +
    theme_minimal() +
    xlab("Sensitivity or true positive rate") +
    ylab("Specificity or true negative rate") +
    theme(legend.position = "none")               
@ 


Accuracy and Kappa of each of the optimized model across all sample groups after grid tuning search.
\marginnote{\small\color{blue}$\Lsh$ Optimized model}[0cm]
<<scatterplot_tuned_accuracyKappa_performance>>=
pak <- df %>%
    select(model, accuracy, kappa) %>%
    unique
df %>%
    ggplot(aes(x = accuracy,
               y = kappa,
               fill = model,
               label = as.factor(model))) +
    geom_point(aes(size = 4,
               color = model)) +
    geom_label_repel(data = subset(pak, accuracy >= .6 & kappa >= .4),
                    nudge_x = -.2,
                    force = 1,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
    theme_minimal() +
    xlab("Accuracy of the trained model (testing)") +
    ylab("Kappa on how well the classifier performed compared to chance") +
    theme(legend.position = "none")               
@ 


Accuracy versus the p-value of each classification. The p-value is a hypothesis test between predicting expected samples and the probability that the classification is biased by disproportionate class sizes (one group of samples is larger than an other).
<<scatterplot_tuned_accuracyPval_performance>>=
paap <- df %>%
    select(model, accuracy, accuracyPval) %>%
    unique
p <- df %>% 
    ggplot(aes(x = accuracyPval,
               y = accuracy,
               label = as.factor(model),
               fill = model)) +
    geom_point(aes(size = 3,
               fill = model),
               shape = 21,
               position=position_jitter(width=.01,height=.01)) +
    geom_label_repel(data = subset(paap, accuracy >= .65 & accuracyPval <= .01),
                    nudge_x = .2,
                    force = 1,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 3) +
##    scale_x_reverse(limits = rev(levels(df$accuracyPval))) +
    theme_minimal() +
    ylab("Accuracy") +
    xlab("P-value between correct prediction and false no-information classification") +
    theme(legend.position = "none")               

    ggMarginal(p, type = "histogram", fill="transparent")


@ 


Prevalence of cases for each classifier. Were the classes perfectly balanced? A positive predictive score is similar to precision while accounting for disproportionality of the classes.
<<scatterplot_tuned_prevalence_performance>>=
pbd <- df %>%
    select(group, model, Balanced.Accuracy, Detection.Prevalence)
df %>% 
    ggplot(aes(x = Balanced.Accuracy,
               y = Detection.Prevalence,
               label = as.factor(model),
               fill = model)) +
    geom_point(aes(size = 2,
               color = model,
               shape = as.factor(group))) +
    geom_label_repel(data = subset(pbd, Balanced.Accuracy >= .72),
                    nudge_x = -.1,
                    nudge_y = .5,                   
                    force = 15,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    facet_wrap(~ group, ncol = 1) +
    theme_minimal() +
    xlab("Balanced accuracy by sample classes") +
    ylab("Prevalence") +
    theme(legend.position = "none")               
    
@ 



\subsubsection{Probability to classify samples with the best model}
\label{subsec:bestmod}

Using the best model, support vector machines with a polynomial kernel, gets the cleanest predictions of individuals with of CNS and systemic relapse.
<<density_stacked_bestmod_probabilities>>=
dfp <- read.table("./data/reports.437017/log.performance6.class_probabilities.seed5437259.437017.txt", row.names = 1, header = T)

dfm = NULL
classes.s <- c("CNS", "NOREL", "SYST")
for (cp in 1:3) {
    dfmx <- dfp %>% 
        select(one_of("original", classes.s[[cp]])) %>%
        filter(original == classes.s[[cp]])
    dfm <- rbind(dfm, data.frame(original = classes.s[[cp]],
                                 grp.mean = mean(dfmx[,2])))
}

dfp %>% 
    gather("class", "prob", 3:5) %>%
    ggplot(aes(x = prob,
               fill = class)) +
##    geom_density(alpha = 0.3) +
    geom_density(position = "stack") +    
##    geom_area(aes(fill = class), stat ="bin", alpha=0.6) +
    geom_vline(data = dfm, mapping = aes(xintercept=grp.mean), linetype = "dashed") +
    scale_x_continuous(breaks = pretty(dfp$CNS, n = 10)) +    
    theme_minimal() +
    facet_wrap( ~ original,
               ncol = 1,
               scales = "free") +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Density (fitted probabilities with lambda = 1)")
@ 

Similar to the above but non stacked densities.
\marginnote{\small\color{blue}$\Lsh$ similar \& optional representation}[0cm]
<<density_bestmod_probabilities>>=
dfp %>% 
    gather("class", "prob", 3:5) %>%
    ggplot(aes(x = prob,
               fill = class)) +
    geom_density() +    
    geom_vline(data = dfm, mapping = aes(xintercept=grp.mean), linetype = "dashed") +
    scale_x_continuous(breaks = pretty(dfp$CNS, n = 10)) +    
    theme_minimal() +
    facet_wrap( ~ original,
               ncol = 1,
               scales = "free") +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Density (fitted probabilities with lambda = 1)")
@ 

Bars showing concentration of good predictions by individual for each outcome class.
\marginnote{\small\color{blue}$\Lsh$ similar \& optional representation}[0cm]
<<histogram_bestmod_probabilities>>=
dfp %>%  
    gather("class", "prob", 3:5) %>%
    ggplot(aes(x = prob,
               fill = original)) +
    geom_histogram(binwidth = 0.01, col = "black", size = .1) +
    theme_minimal() +
    facet_wrap( ~ class,
               ncol = 1,
               scales = "free") +
    theme(legend.position = "top") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Fitted probabilities with lambda = 1")
@ 

Distribution of probabilities for individuals identified with risk of central nervous system relapse.
<<bar_cns_Distribution_bestmod_probabilities>>=
dfp %>% 
    select(original, CNS) %>%
    filter(original == "CNS") %>%
    ggplot(aes(x=CNS)) +
    geom_histogram(binwidth = 0.045, color = "white", fill = "steelblue") +
    theme_minimal() +
    scale_x_continuous(breaks = pretty(dfp$CNS, n = 10)) +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Fitted probabilities with lambda = 1")
@ 

Distribution of probabilities for individuals identified with risk of a systemic relapse.
<<bar_syst_Distribution_bestmod_probabilities>>=
dfp %>% 
    select(original, SYST) %>%
    filter(original == "SYST") %>%
    ggplot(aes(x=SYST)) +
    geom_histogram(binwidth = 0.045, color = "white", fill = "steelblue") +
    theme_minimal() +
    scale_x_continuous(breaks = pretty(dfp$SYST, n = 10)) +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Fitted probabilities with lambda = 1")
@ 

Distribution of probabilities for individuals identified with a no risk of relapse after treatment, at the time of diagnosis.
<<bar_norel_Distribution_bestmod_probabilities>>=
dfp %>% 
    select(original, NOREL) %>%
    filter(original == "NOREL") %>%
    ggplot(aes(x=NOREL)) +
    geom_histogram(binwidth = 0.045, color = "white", fill = "steelblue") +
    theme_minimal() +
    scale_x_continuous(breaks = pretty(dfp$NOREL, n = 10)) +
    labs(x = "Probability of selected genes to predict different patient classes",
         y = "Fitted probabilities with lambda = 1")
@ 


\subsection{Importance scope of gene contribution}
\label{subsec:importance}
Importance scores of each gene is calculated based on that variable significance to the model performance. The score is thus model-based therefore taking into account the estimated correlation between predictors. 
For each class, a gene is attributed an importance. All counts are scaled to 100. 
A trapezoid rule is used to approximate an integral with linear guidelines. This helps estimate an area under the ROC curve. The area is used to measure the variable importance.
\marginnote{\small\color{blue}$\Lsh$Multiclass pairwise decomposition AUROC}[0cm]
<<importance_metrics_svmpoly, out.width='5in'>>=
imp.model <- read.table("./data/reports.437017/log.performance5.importance.seed5437259.437017.txt", header = T)
imp.model %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>%         
    filter(model == "svmPoly") %>%
    gather("groups", "importance", 3:5) %>% 
    ggplot(aes(x = reorder(genes, importance),
               y = importance,
               fill = as.character(groups))) +
    geom_point(shape=21) +
    geom_segment(aes(y = 50, 
                   x = genes,
                   yend = importance,
                   xend = genes), 
               color = "black") +
    facet_wrap(~ groups, ncol = 3) +
    theme_minimal() +
    coord_flip() +
    ylab("Importance metric based on AUROC") +
    xlab("") +
    theme(axis.text.y = element_text(size = 6)) +
    theme(legend.position = "none")

@ 

Genes ranked by importance across all classes. The bigger the bubble, the more models were to rely on that one gene.
<<importance_bestgenes_models, out.width='5in'>>=
imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    gather("groups", "importance", 3:5) %>%
    filter(importance >= 80) %>%
    ggplot(aes(x = reorder(genes, importance),
               y = importance,
               color = groups)) +
    geom_count(col="tomato3", show.legend=F) +
    theme_minimal() +
    ylab("Genes with importance over 80 across all classes") +
    xlab("") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8)) +
    theme(legend.position = "top")

@ 


Comparing the importance of genes across all model trained and optimized, annotated by genes, only for the SVM model with a polynomial kernel. Model comparison between individuals diagnosed with CNS relapse or no relapse.
<<importance_metrics_all_cnsNOREL>>=
model.names <- imp.model %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>%     
    select(genes, CNS, NOREL, model) %>%
    filter(model == "svmPoly")

p <- imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>%     
    ggplot(aes(x = CNS,
               y = NOREL,
               label = genes)) +
    geom_smooth(method = 'loess', alpha=1) +
    geom_point(aes(fill = model), shape=21,
               position=position_jitter(width=1.5,height=1.5)) +
    theme_minimal() +
    geom_text_repel(data = subset(model.names, CNS >= 50),
                    nudge_x = 20,
                    nudge_y = -20,                    
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    xlab("CNS importance metrics for SVM polynomial") +
    ylab("NOREL importance metrics") +
    theme(axis.text.y = element_text(size = 6)) +
    theme(legend.position = "none")

    ggMarginal(p, type = "histogram", fill="transparent")
@ 

Comparing the importance of genes across all model trained and optimized, annotated by genes, only for the SVM model with a polynomial kernel. Model comparison between individuals diagnosed with CNS relapse or systemic.
<<importance_metrics_all_cnsSYST>>=
model.names <- imp.model %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    select(genes, CNS, SYST, model) %>%
    filter(model == "svmPoly")

p <- imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    ggplot(aes(x = CNS,
               y = SYST,
               label = genes)) +
    geom_smooth(method = 'loess', alpha=1) +
    geom_point(aes(fill = model), shape=21,
               position=position_jitter(width=1.5,height=1.5)) +
    theme_minimal() +
    geom_text_repel(data = subset(model.names, CNS >= 50),
                    nudge_x = 20,
                    nudge_y = -20,                    
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    xlab("CNS importance metrics for SVM polynomial") +
    ylab("SYST importance metrics") +
    theme(axis.text.y = element_text(size = 6)) +
    theme(legend.position = "none")

    ggMarginal(p, type = "histogram", fill="transparent")
@ 


Comparing the importance of genes across all model trained and optimized, annotated by genes, only for the SVM model with a polynomial kernel. Model comparison between individuals diagnosed with systemic or no relapse.
<<importance_metrics_all_systNOREL>>=
model.names <- imp.model %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    select(genes, SYST, NOREL, model) %>%
    filter(model == "svmPoly")

p <- imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    ggplot(aes(x = SYST,
               y = NOREL,
               label = genes)) +
    geom_smooth(method = 'loess', alpha=1) +
    geom_point(aes(fill = model), shape=21,
               position=position_jitter(width=1.5,height=1.5)) +
    theme_minimal() +
    geom_text_repel(data = subset(model.names, SYST >= 50),
                    nudge_x = 20,
                    nudge_y = -20,                    
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    xlab("SYST importance metrics for SVM polynomial") +
    ylab("NOREL importance metrics") +
    theme(axis.text.y = element_text(size = 6)) +
    theme(legend.position = "none")

    ggMarginal(p, type = "histogram", fill="transparent")
@ 


\subsection{Accuracy measured across pipelines}
\label{subsec:pipes}
Different strategies for gene filtering can be used, either at different thresholds for some methods and implementing or not a method can produce a different accuracy. 
The performance was measured for SVM model with a polynomial kernel.
Metrics were registered manually after the execution of the whole pipeline (from gene expression, to networks, and finally classification).
\marginnote{\small\color{blue}$\Lsh$ Final model is wo variance shrinking, wo ctrl, w nets, w L1}[0cm]
<<accuracy_across_pipelines>>=
pipelines <- c("variance shrinking +",
               "Low variance -",
               "variance shrinking -",
               "Clusters +",
               "Clusters -", 
               "L1 -",
               "Ctrl -",
               "Final model")
perf.estimated <- c(.61, .59, .59, .65, .62, .67, .71, .78)
dfpe <- data.frame(pipelines = as.factor(pipelines), accuracy = perf.estimated)
dfpe %>%
    arrange(accuracy) %>%
    mutate(pipelines = factor(pipelines, pipelines)) %>%
    ggplot(aes(x = reorder(pipelines, accuracy),
               y = accuracy)) +
    geom_point(stat = "identity",
               size=3, shape=21,
               fill = "red") +
    geom_line(aes(x = as.integer(pipelines))) +
    xlab("Pipelines tested at different thresholds") +
    ylab("Performance of model accuracy after multi-class optimization") +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))
    
@ 


\subsection{Expression of important genes summarized by RMA scores}
\label{subsec:expression}
The expression is based on RMA normalized likelihoods for 230 individuals.
Genes with importance score above 90.
<<important_genes>>=
rma.genes <- read.table("./data/expressions.epochs50", header = TRUE)
sel.genes <- imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    gather("groups", "importance", 3:5) %>%
    filter(importance >= 90) %>% 
    select(genes) %>%
    unique

sel.genes
@ 


Create a forest plot of all important genes
<<forestplot_function>>=
gene.by.forest <- function(datx = rma.genes, y = meta.selected$Groups){
  dat <- data.frame(y, t(datx))
  selx <- NULL
  for(i in 1:nrow(sel.genes) ){
    sels <- dat %>%
    select(contains(sel.genes$genes[i])) %>%
    mutate(gene = sel.genes$genes[i]) %>%
    mutate(groups = y)
    colnames(sels) <- c("expression", "gene", "groups")

    selx <- rbind(selx, sels)
  }
  sel.se <- summary_SE(selx, measurevar = "expression", groupvars = c("gene","groups"))

  sel.se %>%
      ggplot(aes(x = reorder(gene, expression),
                 y = expression, 
                 ymin = c(expression-se), 
                 ymax=c(expression+se))) +
      xlab("") + 
      ylab("Normalized gene expression (RMA)")+
      geom_errorbar(aes(ymin=expression-se,
                        ymax=expression+se),
                    width=0,
                    position=position_dodge(.9)) +
      geom_pointrange(aes(col=groups), 
                      size = 0.5, shape = 15)+
      coord_flip() +
      theme_minimal() +
      theme(legend.position = "top")
  
}
@ 


Comparing important genes by patient relapse prognosis.
<<forestplot_cns_important_genes>>=
gene.by.forest(datx = rma.genes, y = meta.selected$Groups)
@ 

Comparing important genes by patient cell-of-origin prognosis.
<<forestplot_coo_important_genes>>=
gene.by.forest(datx = rma.genes, y = meta.selected$Contrast1)
@ 

Comparing important genes by patient nodal involvement prognosis.
<<forestplot_nodes_important_genes>>=
gene.by.forest(datx = rma.genes, y = meta.selected$Contrast2)
@ 

Define function that combines samples, RMA-normalized log2 fold changes, and prognosis classes. Generates plots.
<<expression_rma>>=
gene.by.class <- function(data = rma.genes, y = meta.selected$Groups, geneSel = 1, implev = 90){
    y.samples <- y
    dat <- data.frame(y.samples, t(data))

    ## get top genes
    sel.genes <- imp.model %>% 
        mutate(genes = gsub(".TC.*$","",genes)) %>% 
        gather("groups", "importance", 3:5) %>%
        filter(importance >= implev) %>% 
        select(genes) %>%
        unique

    ## get expression of each gene for each class
    sel.box <- dat %>%
        select(contains(sel.genes$genes[geneSel])) %>%
        mutate(groups = y.samples)
    colnames(sel.box) <- c("gene", "groups")

    sel.box %>%
        arrange(gene) %>%
        ggplot(aes(x = reorder(groups, gene),
                   y = gene,
                   color = groups)) +
        geom_boxplot(outlier.colour = NA, lwd = .4) +
        geom_jitter(aes(color = factor(groups)),
                    shape=16,
                    position=position_jitterdodge(dodge.width=.8),
                    cex = 2) +
        scale_color_brewer(palette="Paired") +
        theme_minimal() +
        theme(legend.position = "none") +
        xlab("") + ylab(paste0(sel.genes$genes[geneSel])) +
        theme(axis.text.x = element_text(vjust = .5,
                                         angle = 45,
                                         size = 10))
}
@ 

We choose the genes with the top important score, above than 90.
CXRC4
<<expression_cxcr4>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 1, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 1, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 1, implev = 90)
@ 

NFMA1 
<<expression_nfam1>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 2, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 2, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 2, implev = 90)
@ 

AC006547.8
<<expression_ac006547>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 3, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 3, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 3, implev = 90)
@ 

ALDH1A3
<<expression_aldh1a3>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 4, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 4, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 4, implev = 90)
@ 

ITGAE
<<expression_itgae>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 5, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 5, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 5, implev = 90)
@ 

TRDJ1
<<expression_trdj1>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 6, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 6, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 6, implev = 90)
@ 

ASB7
<<expression_asb7>>=
gene.by.class(data = rma.genes, y = meta.selected$Groups, geneSel = 7, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast1, geneSel = 7, implev = 90)
gene.by.class(data = rma.genes, y = meta.selected$Contrast2, geneSel = 7, implev = 90)
@ 


\subsection{Expression of important genes summarized by limma scores}
\label{subsec:expression}
Expression based on log2 fold change for individuals compared based on a relapse contrast.
<<expression_stacked_relapse>>=
pvals <- read.table("./data/pvals.lmfit", header = TRUE)

pvals %>% 
    filter(Contrast == "systemicRelapse") %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    ggplot(aes(x = reorder(genes, LogFC),
               y = LogFC,
               fill = factor(Comparison))) +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    scale_fill_brewer(palette="Paired") +
    facet_wrap(~ Comparison, ncol = 1) +
    theme_minimal() +
    theme(legend.position = "none") +
    xlab("") +
    ylab("Log2 ratios of fold change after RMA quantile normalization (2 is 4-fold up)")

@ 

Expression based on log2 fold change for individuals compared based on involvement of lymphnodes or extra nodal sites.
<<expression_stacked_nodes>>=
pvals %>%
    filter(Contrast == "systemicRelapseNodes") %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    ggplot(aes(x = reorder(genes, LogFC),
               y = LogFC,
               fill = factor(Comparison))) +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    scale_fill_brewer(palette="Paired") +
    facet_wrap(~ Comparison, ncol = 2) +
    theme_minimal() +
    theme(legend.position = "none") +
    xlab("") +
    ylab("Log2 ratios of fold change after RMA quantile normalization (2 is 4-fold up)")

@ 

Expression based on log2 fold change for individuals compared based on involvement of cell-of-origin.
<<expression_stacked_coo>>=
pvals %>%
    filter(Contrast == "systemicRelapseCOOprediction") %>%
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    ggplot(aes(x = reorder(genes, LogFC),
               y = LogFC,
               fill = factor(Comparison))) +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    scale_fill_brewer(palette="Paired") +
    facet_wrap(~ Comparison, ncol = 2) +
    theme_minimal() +
    theme(legend.position = "none") +
    xlab("") +
    ylab("Log2 ratios of fold change after RMA quantile normalization (2 is 4-fold up)")

@ 

Expression based on log2fold and adjusted p-values. Labeled genes have a minimum of 0.1 adjusted p-value. Duplication in gene names is possible, because each contrast uses different comparisons between the groups of individuals.
<<expresion_scatterplot_fdr>>=
model.names <- pvals %>%
    filter(FDRadjPval <= .1)

pvals %>% 
    ggplot(aes(x = FDRadjPval,
               y = LogFC,
               color = Contrast,
               label = Symbol)) +
    geom_point(aes(color = Contrast),
#               shape = as.factor(Contrast)),
               size = 2) +
    geom_text_repel(data = subset(model.names, FDRadjPval <= .1),
                    nudge_x = -.5,
                    nudge_y = -.1,                    
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2.5) +
    scale_fill_brewer(palette="Paired") +
    theme_minimal() +
    theme(legend.position = "top") +
    xlab("False discovery rate adjusted p-value") +
    ylab("Log2 scaling of expression after RMA quantile normalization (2 is 4-fold up)")

@ 

Expression based on log2fold and B-statistics. Labeled genes have a minimum of 0 B-statistic score (ie., 53\% probability of being significant). Duplication in gene names is possible, because each contrast uses different comparisons between the groups of individuals.
<<expresion_scatterplot_bval>>=
model.names <- pvals %>%
    filter(B >= 0)

pvals %>%
    ggplot(aes(x = B,
               y = LogFC,
               color = Contrast,
               label = Symbol)) +
    geom_point(aes(color = Contrast),
#               shape = as.factor(Contrast)),
               size = 2) +
    geom_text_repel(data = subset(model.names, B >= 0),
                    nudge_x = 1.5,
                    nudge_y = -.1,
                    force = 5,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2.5) +
    scale_fill_brewer(palette="Dark2") +
    theme_minimal() +
    theme(legend.position = "top") +
    xlab("B-statistic at 53% chance of being significant") +
    ylab("Log2 scaling of expression after RMA quantile normalization (2 is 4-fold up)")

@ 

\subsection{All classifying genes visualized by prognosis classes}
\label{subsec:heatmaps}
Without clustering, visualizing the expression of all selected genes used for classification. Log2 FC was scaled to 0-1 for better interpretability.\\

\subsubsection{Top classifier genes}
\label{subsec:topclass}
Gene log2 ratios for individuals when grouped according to CNS or systemic relapse, or no relapse.
<<heatmap_no_clustering_relapse>>=
data.frame(y=meta.selected$Groups, t(rma.genes)) %>%
    melt() %>% 
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>% 
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "white", high = "#fdc086") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 

Gene log2 ratios for individuals when grouped according to lymphnodes or extranodal involvement.
<<heatmap_no_clustering_nodes>>=
data.frame(y=meta.selected$Contrast2, t(rma.genes)) %>%
    melt() %>% 
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>% 
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "white", high = "#beaed4") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 

Gene log2 ratios for individuals when grouped according to cell-of-origin.
<<heatmap_no_clustering_coo>>=
data.frame(y=meta.selected$Contrast1, t(rma.genes)) %>%
    melt() %>%
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>%
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "white", high = "#7fc97f") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 

\subsubsection{Top importance genes}
\label{subsec:topimportance}
The selected genes with highest importance score across models, showing log2 ratios for individuals when grouped according to relapse classes.
<<heatmap_no_clustering_importance_relapse>>=
sel.genes <- imp.model %>% 
    mutate(genes = gsub(".TC.*$","",genes)) %>% 
    gather("groups", "importance", 3:5) %>%
    filter(importance >= 90) %>% 
    select(genes) %>%
    unique

data.frame(y=meta.selected$Groups, t(rma.genes)) %>%
    melt() %>%
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>%
    filter(genes == sel.genes$genes) %>% 
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "#ffffcc", high = "#1f78b4") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 

The selected genes with highest importance score across models, showing log2 ratios for individuals when grouped according to nodal classes.
<<heatmap_no_clustering_importance_nodes>>=
data.frame(y=meta.selected$Contrast2, t(rma.genes)) %>%
    melt() %>%
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>%
    filter(genes == sel.genes$genes) %>% 
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "#ffffcc", high = "#1f78b4") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 


The selected genes with highest importance score across models, showing log2 ratios for individuals when grouped according to cell-of-origin.
<<heatmap_no_clustering_importance_coo>>=
data.frame(y=meta.selected$Contrast1, t(rma.genes)) %>%
    melt() %>%
    ddply( .(variable), transform, rescale = rescale(value)) %>% 
    mutate(genes = gsub(".TC.*$","",variable)) %>%
    filter(genes == sel.genes$genes) %>% 
    ggplot(aes(y, genes)) +
    geom_tile(aes(fill = rescale), colour = "white") +
    scale_fill_gradient(low = "#ffffcc", high = "#1f78b4") +
    xlab("") + ylab("") +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6)) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 9))

@ 







\subsection{Version of machine learning models on high performance clusters}
\label{subsec:version}
\marginnote{\small\color{blue}$\Lsh$ Version of R packages used in the machine learning pipeline}[0cm]

<<>>=
#######################################################################################
## R version 3.5.0 (2018-04-23)                                                      ##
## Platform: x86_64-pc-linux-gnu (64-bit)                                            ##
## Running under: Ubuntu 16.04.4 LTS                                                 ##
##                                                                                   ##
## Matrix products: default                                                          ##
## BLAS: /usr/lib/openblas-base/libblas.so.3                                         ##
## LAPACK: /usr/lib/libopenblasp-r0.2.18.so                                          ##
##                                                                                   ##
## locale:                                                                           ##
##  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C                                      ##
##  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8                            ##
##  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8                           ##
##  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                                         ##
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C                                    ##
## [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C                               ##
##                                                                                   ##
## attached base packages:                                                           ##
## [1] stats     graphics  grDevices utils     datasets  methods   base              ##
##                                                                                   ##
## other attached packages:                                                          ##
##  [1] pls_2.6-0          bindrcpp_0.2.2     plot3D_1.1.1       plyr_1.8.4          ##
##  [5] tidyr_0.8.1        reshape2_1.4.3     vegan_2.5-2        permute_0.9-4       ##
##  [9] earth_4.6.3        plotmo_3.4.0       TeachingDemos_2.10 plotrix_3.7-2       ##
## [13] ROCR_1.0-7         doSNOW_1.0.16      snow_0.4-2         iterators_1.0.9     ##
## [17] caret_6.0-80       ggplot2_3.0.0      lattice_0.20-35    glmnet_2.0-16       ##
## [21] foreach_1.4.4      Matrix_1.2-14      dplyr_0.7.6        gplots_3.0.1        ##
## [25] pvclust_2.0-0      RColorBrewer_1.1-2                                        ##
#######################################################################################
@ 



<<>>=
#######################################################################
##  [1] minqa_1.2.4         colorspace_1.3-2    class_7.3-14         ##
##  [4] DRR_0.0.3           svUnit_0.7-12       prodlim_2018.04.18   ##
##  [7] lubridate_1.7.4     codetools_0.2-15    splines_3.5.0        ##
## [10] mnormt_1.5-5        robustbase_0.93-0   RcppRoll_0.2.2       ##
## [13] mda_0.4-10          broom_0.4.4         ddalpha_1.3.3        ##
## [16] cluster_2.0.7-1     kernlab_0.9-26      sfsmisc_1.1-2        ##
## [19] compiler_3.5.0      assertthat_0.2.0    lazyeval_0.2.1       ##
## [22] FCNN4R_0.6.2        Rcgmin_2013-2.21    optextras_2016-8.8   ##
## [25] tools_3.5.0         igraph_1.2.1        misc3d_0.8-4         ##
## [28] gtable_0.2.0        glue_1.2.0          LiblineaR_2.10-8     ##
## [31] naivebayes_0.9.2    Rcpp_0.12.18        gdata_2.18.0         ##
## [34] nlme_3.1-137        setRNG_2013.9-1     psych_1.8.4          ##
## [37] timeDate_3043.102   gower_0.1.2         stringr_1.3.1        ##
## [40] kknn_1.3.1          gtools_3.5.0        DEoptimR_1.0-8       ##
## [43] Rvmmin_2018-4.17    MASS_7.3-50         scales_1.0.0         ##
## [46] ipred_0.9-6         parallel_3.5.0      monmlp_1.1.5         ##
## [49] rpart_4.1-13        stringi_1.2.2       ucminf_1.1-4         ##
## [52] randomForest_4.6-14 deepnet_0.2         e1071_1.6-8          ##
## [55] BB_2014.10-1        caTools_1.17.1      optimx_2013.8.7      ##
## [58] lava_1.6.1          geometry_0.3-6      rlang_0.2.1          ##
## [61] pkgconfig_2.0.1     bitops_1.0-6        purrr_0.2.5          ##
## [64] bindr_0.1.1         recipes_0.1.2       labeling_0.3         ##
## [67] CVST_0.2-2          tidyselect_0.2.4    gbm_2.1.3            ##
## [70] magrittr_1.5        R6_2.2.2            dimRed_0.1.0         ##
## [73] pillar_1.2.3        foreign_0.8-70      withr_2.1.2          ##
## [76] mgcv_1.8-23         survival_2.42-3     abind_1.4-5          ##
## [79] nnet_7.3-12         tibble_1.4.2        KernSmooth_2.23-15   ##
## [82] RRF_1.7             grid_3.5.0          ModelMetrics_1.1.0   ##
## [85] digest_0.6.15       dfoptim_2018.2-1    numDeriv_2016.8-1    ##
## [88] stats4_3.5.0        munsell_0.5.0       magic_1.5-8          ##
## [91] quadprog_1.5-5                                               ##
#######################################################################

@


\section{Clonal evolution}
\label{sec:clonal}
\subsection{Distribution of allele frequency of variants}
\label{subsec:vaf}
Exome sequencing of tumor samples generated several libraries of reads.
Allele frequency distribution was measured by calling variants on the reads files.
These variants were thresholded with P-value at 10e-25, depth of coverage by point mutation at 50, variant allele frequency at 1\% (discard below 1\%), and pyclone normal-minor-major copy numbers at 2-0-2 with major-copy-number sets. 
Also, some variants were removed based on their known locations from VarScan annotations.
<<vaf_pval, out.width='5in'>>=
snv.post.filter <- read.table("./data/output.10_bash.summary.snv.postFilter_VAFpval.txt", header = T, fill = TRUE)

model.names <- snv.post.filter %>%
    mutate(pval = -log10(pval)) %>%    
    filter(vaf >= 35) %>%
    filter(vaf <= 85)

p <- snv.post.filter %>%
    mutate(pval = -log10(pval)) %>%
    ggplot(aes(x = vaf,
               y = pval,
               label = snv,
               fill = sample)) + 
    geom_point(size = 1, shape = 21) +
    geom_label_repel(data = subset(model.names, pval <= 0),
                    nudge_x = 1.5,
                    nudge_y = 200,
                    force = 10,
                    segment.color = "grey50",
                    direction = "y",
                    segment.size = 0.1,
                    size = 2) +
    scale_fill_brewer(palette="Dark2") +
    theme_minimal() +
    xlab("Variant allele frequency (varscan2)") +
    ylab("-log10(P-value)") +
    theme(legend.position = "top")
ggMarginal(p, type = "histogram", fill="transparent")

@ 

Variants and their distribution based on their known locations obtained from VarScan annotations.
<<variant_varscan_functions, out.width='5in'>>=
read.table("./data/output.8_bash.summary.snv_functions.txt", header = TRUE) %>% 
    mutate(fct = gsub("_variant","",fct)) %>%
    mutate(fct = gsub("_"," ",fct)) %>%    
    ggplot(aes(x = reorder(fct, count),
               y = count,
               color = factor(sample))) +
    geom_point(size = 3, shape = "|") +
    coord_flip() +
    scale_color_brewer(palette="Dark2") +
    theme_minimal() +
    theme(legend.position = "top") +
    xlab("") +
    ylab("Variant function allocation (ClinVar 2018)")
@ 


\section{System information for this report}
\label{sec:sys_info}
\noindent
The version number of R and packages loaded for generating the vignette were:
<<sessionInfo>>=
###save(list=ls(pattern=".*|.*"),file="PD.Rdata")
sessionInfo()
@ 



\end{linenumbers}
\end{document}
