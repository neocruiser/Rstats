\documentclass[9pt,english]{extarticle}
\include{canevas_config}

\begin{document}
\author{Sleiman Bassim, PhD}
\title{Descriptive analysis}
\maketitle
\begin{linenumbers}
<<setup, include=FALSE, cache=FALSE>>=
# set global chunk options
opts_chunk$set(dev="postscript",
               fig.path="graphics/",
               fig.lp= "",
               comment=NA,
               fig.keep="high",
               fig.show='hold',
               fig.align='center', 
               out.width='.49\\textwidth',
               tidy.source=TRUE,
               crop=TRUE,
               results="markup",
               warnings=FALSE,
               error=FALSE,
               message=FALSE)
options(formatR.arrow=TRUE,
        width=70,
        digits = 3,
        scipen = 6)
@ 


\maketitle
\tableofcontents
\pagebreak


\noindent
\marginnote{\small\color{blue}$\Lsh$ Project started Dec 10 2017, updated \today}[.1cm]
Loaded functions.
<<loading,results='hide'>>=
#source("/media/Data/Dropbox/humanR/01funcs.R")
rm(list=ls())
#setwd("/media/Data/Dropbox/humanR/PD/")
#setwd("~/Dropbox/humanR/PD/")
###load("PD.Rdata", .GlobalEnv)
#lsos(pat="")
@ 

Loaded packages.
<<packages,results='hide'>>=
pkgs <- c('gdata','lattice','latticeExtra',
          'ggplot2', 'dplyr', 'tidyr', 'RColorBrewer','igraph',
          'DescTools', 'scales', 'brotools', 'Hmisc', 'finalfit',
          'plyr')
lapply(pkgs, require, character.only = TRUE)
@


\section{Data structure}
\label{sec:structure}
Data is from patients with Lymphoma tumors, either undergone or not a Rituximab CHOP treatment. Some patients show relapse after treatment. Tumors migrate though nodal (lymphnodes) or extranodal tissues. Tumors involve two different subtypes of cells of origin, ABC or GCB. \textbf{The first aim is to find correlation genes that respond differently to treatment, nodal transmission, and cell subtypes.}
\marginnote{\small\color{blue}$\Lsh$OR: Odds ratio. HR: Hazard ratio}[0cm]
<<summary_full>>=
#read.table("data/phenodata", sep = "\t", header = T) %>%
#    dplyr::select(SAMPLE_ID, Timepoint, 
#    GROUP, SITE, Score, Prediction, ABClikelihood) %>%
#    brotools::describe()

print_summary_table <- function(features, dependent, df, execute = TRUE) {
    if ( execute == TRUE ) {
        x <- df %>%
            summary_factorlist(dependent, features, p=FALSE, add_dependent_label=TRUE)
        ## print latex table
        Hmisc::latex(x, file = "", booktabs = TRUE, title = "")
    } else {
        cat("LaTeX summary table printed\n")
    }
}

dfs <- read.table("data/phenodata", sep = "\t", header = T)
print_summary_table(features= c("Score", "ABClikelihood", "GROUP"), 
                    dependent= c("Prediction"), 
                    df = dfs, 
                    execute = F)
@ 


\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-2pt}
\begin{tabular}{llllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Prediction}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{ABC}&\multicolumn{1}{c}{GCB}&\multicolumn{1}{c}{U}\tabularnewline
\midrule
10&Score&Mean (SD)&3156.3 (475.5)&506.4 (721.1)&2162.8 (143.6)\tabularnewline
1&ABClikelihood&Mean (SD)&1 (0)&0 (0)&0.5 (0.4)\tabularnewline
2&GROUP&CNS DIAGNOSIS&4 (33.3)&6 (50.0)&2 (16.7)\tabularnewline
3&&CNS RELAPSE CHOP or EQUIVALENT&6 (60.0)&3 (30.0)&1 (10.0)\tabularnewline
4&&CNS RELAPSE RCHOP&17 (44.7)&13 (34.2)&8 (21.1)\tabularnewline
5&&NO RELAPSE&27 (28.1)&52 (54.2)&17 (17.7)\tabularnewline
6&&NORMAL ABC CONTROL&2 (100.0)&0 (0.0)&0 (0.0)\tabularnewline
7&&NORMAL GCB CONTROL&0 (0.0)&4 (100.0)&0 (0.0)\tabularnewline
8&&SYTEMIC RELAPSE NO CNS&31 (48.4)&25 (39.1)&8 (12.5)\tabularnewline
9&&TESTICULAR NO CNS RELAPSE&9 (75.0)&0 (0.0)&3 (25.0)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}


\subsection{Data reformating}
\label{subsec:reformating}

In the first steps of the analysis, the samples will be labeled (supervised) into the following categories (based on patients diagnosis).
<<summary_selected>>=
metadata <- read.table("data/phenodata", sep = "\t", header = T) %>%
    dplyr::select(SAMPLE_ID, Timepoint, GROUP, SITE, Score, Prediction, ABClikelihood) %>%
    filter(Timepoint != "T2") %>%
    mutate(Groups = case_when(GROUP %in% c("CNS_RELAPSE_RCHOP",
                                            "CNS_RELAPSE_CHOPorEQUIVALENT",
                                            "CNS_DIAGNOSIS") ~ "CNS",
                               GROUP %in% c("TESTICULAR_NO_CNS_RELAPSE", "NO_RELAPSE") ~ "NOREL",
                               GROUP == "SYTEMIC_RELAPSE_NO_CNS" ~ "SYST",
                               TRUE ~ "CTRL")) %>%
    mutate(ABClassify = case_when(ABClikelihood >= .9 ~ "ABC",
                                  ABClikelihood <= .1 ~ "GCB",
                                  TRUE ~ "U")) %>%
    mutate(ABCScore = case_when(Score > 2412 ~ "ABC",
                                Score <= 1900 ~ "GCB",
#                                Score == NA ~ "NA",
                                TRUE ~ "U")) %>%
    mutate(Nodes = case_when(SITE == "LN" ~ "LN",
                             SITE == "TO" ~ "LN",
                             SITE == "SP" ~ "LN",
                             TRUE ~ "EN")) %>%
    mutate(Lymphnodes = case_when(Nodes == "LN" ~ 1, TRUE ~ 0))

# make sure all samples preserve their ID
metadata$Groups <- as.factor(metadata$Groups)
metadata$ABClassify <- as.factor(metadata$ABClassify)
metadata$ABCScore <- as.factor(metadata$ABCScore)
metadata$Nodes <- as.factor(metadata$Nodes)
metadata$Lymphnodes <- as.factor(metadata$Lymphnodes)
#brotools::describe(metadata)
print_summary_table(c("ABCScore", "ABClassify", "GROUP"), c("Nodes"), metadata, execute = F)
@ 

\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-2pt}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}\tabularnewline
\midrule
4&ABCScore&ABC&34 (37.0)&58 (63.0)\tabularnewline
5&&GCB&36 (35.0)&67 (65.0)\tabularnewline
6&&U&16 (39.0)&25 (61.0)\tabularnewline
1&ABClassify&ABC&37 (35.9)&66 (64.1)\tabularnewline
2&&GCB&38 (32.5)&79 (67.5)\tabularnewline
3&&U&11 (68.8)&5 (31.2)\tabularnewline
7&GROUP&CNS DIAGNOSIS&7 (63.6)&4 (36.4)\tabularnewline
8&&CNS RELAPSE CHOP or EQUIVALENT&5 (62.5)&3 (37.5)\tabularnewline
9&&CNS RELAPSE RCHOP&20 (51.3)&19 (48.7)\tabularnewline
10&&NO RELAPSE&30 (31.2)&66 (68.8)\tabularnewline
11&&NORMAL ABC CONTROL&2 (NA)&0 (0.0)\tabularnewline
12&&NORMAL GCB CONTROL&0 (0.0)&4 (100.0)\tabularnewline
13&&SYTEMIC RELAPSE NO CNS&10 (15.6)&54 (84.4)\tabularnewline
14&&TESTICULAR NO CNS RELAPSE&12 (100.0)&0 (0.0)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}

\subsubsection{Regression analyses to quantify diagnosis connections}
\label{subsec:regression}
Logistic regression of binomial factoring between nodal/extranodal diagnosis and patients labels for cell-of-origin classification and CNS relapse or systemic relapse.
Regression model summary with odds ratio with 95\% confidence interval to quantify how much nodal and extranodal diagnosis is associated with the cell-of-origin ABC or GCB nature in DLBCL patients with CNS, systemic or no relapse.
<<tabulated_summary_logistic>>=
fit_summary_table <- function(features, dependent, df, method, execute = TRUE) {
    if ( execute == TRUE ) {
        if ( method == "glm" || method == "cox" ) {
            x <- df %>%
                finalfit(dependent, features)
        } else if ( execute == "glmer" ) {
            x <- df %>%
                finalfit(dependent, features, 
                         mixed, random_effect)
        }
        ## print latex table
        Hmisc::latex(x, file = "", booktabs = TRUE, title = "")
    } else {
        cat("LaTeX summary table printed\n")
    }
}


fit_summary_table(features= c("ABCScore", "ABClassify", "GROUP"),
                  dependent= c("Nodes"), 
                  df = metadata,
                  method = "glm",
                  execute = F)
@ 




\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-5pt}
\begin{tabular}{lllllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}&\multicolumn{1}{c}{OR (univariable)}&\multicolumn{1}{c}{OR (multivariable)}\tabularnewline
\midrule
4&ABCScore&ABC&34 (39.5)&58 (38.7)&-&-\tabularnewline
5&&GCB&36 (41.9)&67 (44.7)&1.09 (0.61-1.96, p=0.771)&0.44 (0.06-3.23, p=0.408)\tabularnewline
6&&U&16 (18.6)&25 (16.7)&0.92 (0.43-1.97, p=0.820)&0.96 (0.25-4.74, p=0.952)\tabularnewline
1&ABClassify&ABC&37 (43.0)&66 (44.0)&-&-\tabularnewline
2&&GCB&38 (44.2)&79 (52.7)&1.17 (0.67-2.04, p=0.591)&1.61 (0.24-10.98, p=0.615)\tabularnewline
3&&U&11 (12.8)&5 (3.3)&0.25 (0.08-0.76, p=0.018)&0.52 (0.07-2.97, p=0.473)\tabularnewline
7&GROUP&CNS DIAGNOSIS&7 (8.1)&4 (2.7)&-&-\tabularnewline
8&&CNS RELAPSE CHOP or EQUIVALENT&5 (5.8)&3 (2.0)&1.05 (0.15-7.08, p=0.960)&0.97 (0.13-6.76, p=0.979)\tabularnewline
9&&CNS RELAPSE RCHOP&20 (23.3)&19 (12.7)&1.66 (0.43-7.21, p=0.470)&1.71 (0.42-7.73, p=0.461)\tabularnewline
10&&NO RELAPSE&30 (34.9)&66 (44.0)&3.85 (1.08-15.64, p=0.042)&3.40 (0.91-14.2, p=0.074)\tabularnewline
11&&NORMAL ABC CONTROL&2 (2.3)&0 (0.0)&0.00 (NA-NA, p=0.995)&0.00 (NA-NA, p=0.995)\tabularnewline
12&&NORMAL GCB CONTROL&0 (0.0)&4 (2.7)&74.56 (0.00-NA, p=0.993)&79.25 (0.00-NA, p=0.993)\tabularnewline
13&&SYTEMIC RELAPSE NO CNS&10 (11.6)&54 (36.0)&9.45 (2.42-NA, p=0.002)&8.07 (1.98-NA, p=0.004)\tabularnewline
14&&TESTICULAR NO CNS RELAPSE&12 (14.0)&0 (0.0)&0.00 (0.00-NA, p=0.988)&0.00 (0.00-NA, p=0.988)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}



Mixed effects multilevel logistic regression model fit to find connections between patients (CNS relapse, systemic, and no relapse) and cell-of-origin predictions (ABC, GCB likelihoods), while considering nodal and extranodal involvement in the relapse (diagnosed tissue sites with cancer invasion).
<<tabulated_summary_mixed>>=
mixed = c("GROUP")
random_effect = c("SITE")
fit_summary_table(features= c("Prediction", "GROUP"),
                  dependent= c("Nodes"),
                  df = metadata,
                  method = "glmer",
                  execute = F)

@ 


\begin{table}[!h]
\begin{center}
\small\addtolength{\tabcolsep}{-5pt}
\begin{tabular}{lllllll}
\toprule
\multicolumn{1}{l}{}&\multicolumn{1}{c}{Dependent: Nodes}&\multicolumn{1}{c}{}&\multicolumn{1}{c}{EN}&\multicolumn{1}{c}{LN}&\multicolumn{1}{c}{OR (univariable)}&\multicolumn{1}{c}{OR (multilevel)}\tabularnewline
\midrule
9&Prediction&ABC&34 (40.5)&58 (38.7)&-&-\tabularnewline
10&&GCB&36 (42.9)&67 (44.7)&1.09 (0.61-1.96, p=0.771)&-\tabularnewline
11&&U&14 (16.7)&25 (16.7)&1.05 (0.48-2.32, p=0.908)&-\tabularnewline
1&GROUP&CNS DIAGNOSIS&7 (8.1)&4 (2.7)&-&-\tabularnewline
2&&CNS RELAPSE CHOP or EQUIVALENT&5 (5.8)&3 (2.0)&1.05 (0.15-7.08, p=0.960)&0.38 (0.00-NA, p=0.989)\tabularnewline
3&&CNS RELAPSE RCHOP&20 (23.3)&19 (12.7)&1.66 (0.43-7.21, p=0.470)&0.49 (0.00-NA, p=0.988)\tabularnewline
4&&NO RELAPSE&30 (34.9)&66 (44.0)&3.85 (1.08-15.64, p=0.042)&1.70 (0.00-NA, p=0.989)\tabularnewline
5&&NORMAL ABC CONTROL&2 (2.3)&0 (0.0)&0.00 (NA, p=0.995)&0.00 (0.00-Inf, p=1.000)\tabularnewline
6&&NORMAL GCB CONTROL&0 (0.0)&4 (2.7)&NA (0.00-NA, p=0.993)&285412.87 (0.00-Inf, p=0.999)\tabularnewline
7&&SYTEMIC RELAPSE NO CNS&10 (11.6)&54 (36.0)&9.45 (2.42-42.22, p=0.002)&1.76 (0.00-NA, p=0.989)\tabularnewline
8&&TESTICULAR NO CNS RELAPSE&12 (14.0)&0 (0.0)&0.00 (0.00-NA, p=0.988)&0.00 (0.00-Inf, p=1.000)\tabularnewline
\bottomrule
\end{tabular}\end{center}
\end{table}


\subsection{Featured data and groups of sample cases}
\label{subsec:groups}
Difference in cases being indexed based on their \textit{cell-of-origin} association subtypes using either of the following features: prediction, ABClassify, ABCScore.
<<cells_difference>>=
metadata %>%
    select(Prediction, ABClassify, ABCScore) %>%
    summary

@ 


Distribution of samples with different treatments.
<<treatments_bar>>=
metadata %>% 
    select(GROUP) %>%
    ggplot(aes(x = GROUP)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of lymphoma cases",
         x = "Patients diagnosis") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as a pie chart.
<<treatments_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$GROUP)))
pie(table(metadata$GROUP), col=palette.pies.adj)
@ 

Distribution of samples with different cells of origin subtypes.
<<subtypes_bar>>=
metadata %>% 
    select(Prediction) %>%
    ggplot(aes(x = Prediction)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of Cell-of-origin subtypes",
         x = "Patients Cell-of-origin classification") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as pie chart.
<<subtypes_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$Prediction)))
pie(table(metadata$Prediction), col=palette.pies.adj)
@ 

Distribution of samples with different lymphnodes and extranodal cancer metastasis.
<<nodes_bar>>=
par(mfrow=c(2,2))
metadata %>% 
    select(SITE) %>%
    ggplot(aes(x = SITE)) +
    geom_histogram(stat = "count") +
    labs(y = "Number of Nodata origins",
         x = "Patients lymphnodes and extranodal tumor presence") +
    theme_bw() +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@

Or as a pie chart.
<<nodes_pie>>=
palette.pies <- brewer.pal(12, name = "Set3")
palette.pies.adj <- colorRampPalette(palette.pies)(length(unique(metadata$SITE)))
pie(table(metadata$SITE), col=palette.pies.adj)
@ 



\section{Differential expression of microarray Affymetrix data}
\label{sec:expression}
Genes have been fitted in a model that is based on an Empirical Bayes approach. Ranking of the genes determine if they are statistically significant. Bonferroni correction is used to control the false discovery rate (FDR). Moderated t-statistics, FDR, and fold change (log2) are implemented to reduce selection of false positives.

\begin{itemize}
\item \textbf{adjpval} is the adjusted P-value to control the FDR using Bonferroni correction. \textbf{Genes selected here based on their adjpval are also greater than or equal to the bstat threshold}.
\item \textbf{avgex} is the average expression the ordinary arithmetic average of the log2-expression values for the probe, across all arrays. \textbf{Genes selected here based on their avgex are also greater than or equal to the bstat threshold}.
\item \textbf{bstat} is the moderated t-statistics using an Empirical Bayes approach generating B-statistics scores. 
\end{itemize}

<<summary_expression>>=
expression <- read.table("data/summary.full.90800.txt", sep = "\t", header = T) %>%
    select(Design, Model, Bthreshold, adjPval, Category, Parameter, Transcripts) %>%
    filter(Category == "total")
summary(expression)
@ 

Number of transcripts when comparing B-statistics scores, which represent confidence in selecting each significantly expressed gene.
<<transcripts_bval>>=
aggregate( Transcripts ~ Bthreshold, data=expression, FUN=range)

@ 

Number of transcripts when samples are classed into groups, which are based on clinical data (e.g., cell-of-origin, CNS relapse, and nodal/extranodal tumor transmission).
<<transcripts_model>>=
aggregate( Transcripts ~ Model, data=expression, FUN=range)

@ 

Number of transcripts found when comparing different sample cases indexed based on their clinical data.
<<transcripts_design>>=
aggregate( Transcripts ~ Design, data=expression, FUN=range)
@ 


Number of genes that respond to treatment, cell subtypes, and nodal transmission.
<<expression_bval,out.width='5in'>>=

expression %>%
    ggplot(aes(
        x = Design,
        y = Transcripts,
        fill = factor(Bthreshold))) +
    theme_bw() +
    geom_bar(stat = "identity",
             position = "dodge") +
    coord_flip() +
    facet_wrap( ~ Model,
              ncol = 2,
               scales = "free") + 
    scale_fill_brewer(type = "qual", palette = 6) +
    labs(x = "Samples being compared",
         y = "Number of genes") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))


@ 

\subsection{Cleaning and removing non-essential genes}
\label{subsec:subsetting}
\marginnote{\small\color{blue}$\Lsh$ $\sigma^2$ is the average of the squared differences from the $\mu$}[0cm]
Subsetting the data by reducing the number of gene profiles improves interpretation and reduces noise. It is well established that many machine learning models used for classification can be sensitive to high number of \textit{irrelevant} genes, others like support vector machines and random forests are less so \href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-319}{(Statnikov 2008)}.


Each array contains probes of 75,523 functional and non-functional RNAs. Either ncRNA, mRNA, and non annotated genes. More than 53.32\% of the probes are non-coding. For interpretation purpose, ncRNAs profiles were discarded before fitting the expressions. In addition, the variation from the mean of each transcript was assessed and the spread of expression were all used to discard top and bottom variants. Individual genes that vary widely from the mean of the array were removed thus reducing the spread of the expression across profiles. Transcripts with potential biased high expressions were thus flagged and discarded thus improving correlation of other transcripts.
Subsetting was done after normalization of all datasets, all arrays. This would reduce technical errors appearing significant when comparing arrays between each others. Data was transformed (standardization protocol) before calculating means and variances. This helps a better signal recovery from a large dataset with potential expression bias.
\marginnote{\small\color{blue}$\Lsh$ Each array correspond to a DLBCL patient's case}[0cm]

\subsubsection{Variance optimization for each array}
\label{subsec:variance}
Full probe list accounting for 75,523 genes ({\color{red} red horizontal line}). The full line represents the variance after being adjusted by iteratively discarding top/low variant expression profiles. The dotted line represent the original variance before discarding genes.
\marginnote{\small\color{blue}$\Lsh$ The smaller the variance, the better}[0.5cm]

The graph below shows that by discarding highly variant expressions and selecting only the top 1613 genes for example, the mean variance of the whole array (0.27) is higher than a ranked subset of 10,811 (0.09). Ideally, the reduction of the data is on both, the mean variance and mean standard deviation of the whole array.
<<variance_w_ncrna_subsetting>>=
read.table("./data/summary.139102.adjusted.means.subsetting.txt", header = T) %>%
    select(dimension, meanVariance, adj.meanVariance) %>%
    gather("variance", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = dimension)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(variance))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 10)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    geom_hline(aes(yintercept = 75523), colour = "red") +
    labs(y = "Number of selected genes",
         x = "Variance") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 


Same plot description as above however we removed ncRNA which account for 53.32\% of the probes. The total number of transcripts is now 35,253 (46\%, {\color{red} red horizontal line}). The {\color{blue} blue horizontal line} represents the threshold that was selected for subsequent analysis.
\marginnote{\small\color{blue}$\Lsh$ 29,207 genes were selected for clustering and nets}[0cm]


By discarding 1198 transcripts from the 35,253 the top outliers with high variance are not included in the clustering process. More rare expression signals will get distinguished. Also, the size of the dataset was reduced to 29,207 by removing transcripts with little deviation from the mean of each array. The total number of transcripts by array was kept above 25k to increase the sizes of the clusters (modules and networks) in later analyses. For example, network analysis on 20k transcripts generated network sizes between 200 and 500. At 29k networks have a total size over 700 nodes.
<<variance_wo_ncrna_subsetting>>=
read.table("./data/summary.149317.adjusted.means.subsetting.txt", header = T) %>%
    select(dimension, meanVariance, adj.meanVariance) %>%
    gather("variance", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = dimension)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(variance))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    geom_hline(aes(yintercept = 35253), color = "red") +
    geom_hline(aes(yintercept = 29207), color = "blue") +
    labs(y = "Number of selected genes",
         x = "Variance") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 


\subsubsection{Standard deviation optimization for each array }
\label{subsec:deviation}
The spread of the gene expression scores is dependent on their variance, their deviation from each array's mean (population mean). By removing potentially noisy expressions we are reducing the spread of the arrays numbers, hence improving recognition of rare gene regulations.
Below, the plot shows how the standard deviation, \textbf{spread} of the data is getting smaller the more we discard genes with high and low variance.
\marginnote{\small\color{blue}$\Lsh$ Best if small spread between 2 SDs}[0cm]

All array probes with all RNAs.
<<deviation_w_ncrna_subsetting>>=

read.table("./data/summary.139102.adjusted.means.subsetting.txt", header = T) %>%
    select(discarded, meanSD, adj.meanSD) %>%
    gather("sd", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = discarded)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(sd))) +
    geom_point() +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(y = "Number of discarded genes with high variance",
         x = "Standard deviation") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 

Without the ncRNAs. {\color{blue} Blue horizontal line} is the threshold that was selected for later analysis.
<<deviation_wo_ncrna_subsetting>>=
read.table("./data/summary.149317.adjusted.means.subsetting.txt", header = T) %>%
    select(discarded, meanSD, adj.meanSD) %>%
    gather("sd", "count", 2:3) %>%
    ggplot(aes(x = count,
               y = discarded)) +
    theme_bw() +
    geom_line(aes(linetype = as.factor(sd))) +
    geom_point() +
    geom_hline(aes(yintercept = 1198), colour = "blue") +
    scale_x_continuous(trans = "reverse",
                       breaks = scales::pretty_breaks(n = 8)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(y = "Number of discarded genes with high variance",
         x = "Standard deviation") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


\section{Clustering and network analyses}
\label{sec:networks}
The number of clusters and modules per networks are assigned by designing first a similarity matrix between differentially expressed gene for any two conditions (eg., relapse vs no relapse patient cases).
An adjacency matrix is then constructed by weighting the previously inferred measures.
The data is transformed to increase the correlation coefficient therefore improving detection of strong correlated patterns. (Example of the strength of data transformation and correlation, visit the following \href{https://blog.majestic.com/case-studies/correlation-data-transformations/}{online page}).

  \marginnote{\small\color{blue}$\Lsh$Overfitting is a source of bias.}[0cm]
\begin{itemize}
\item \textbf{MaxEdgesPerGene}, maximum number of correlations per genes
\item \textbf{NbNodes}, number of genes found for each edge connection bracket
\item \textbf{Normalization}, method that focuses on creating complete clusters. We tested methods ranging from Complete clustering, Average, and Ward. \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html}{Each method is detailed here.} Only Complete clustering was retained. All other methods overfitted the data.
\item \textbf{Correlation}, finding ranges from linear to non-linear trends. We tested Pearson and Spearman correlation.
\item \textbf{Standardization}, data transformation method. We tested transformation by Hellinger, Standardize, Range, and Logarithmic scaling. \href{http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/decostand.html}{Each method is detailed here.}
\item \textbf{MaxGenePerModule}, how many genes assigned by cluster (module)
\item \textbf{SimilaritySize}, number of initial differentially expressed genes
\item \textbf{EdgeThreshold}, parameter to limit the weight of the edges
\item \textbf{CorrelationPower}, power transformation of the data
\end{itemize}
\marginnote{\small\color{blue}$\Lsh$Effect of correlation methods is seen on module content}[0cm]
<<networks_summary>>=
ns <- read.table("./data/networks.summary.104795.txt", header = T)
summary(ns)
@ 

\marginnote{\small\color{blue}$\Lsh$Test graphs}[0cm]
Difference between methods used for network inference. Are we able to generate convergence of the output of all iterations across all methods?
<<nodes_networks_summary_steps,out.width='5in'>>=

ns %>%
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 

Showing the number of modules per network and the number of genes per module. Each module contains differing number of nodes based on their correlation strength. Each cluster contains at least one module. Each network contains at least one cluster. One module can be assigned to nodes that belong to more than one cluster. The Lowess curves show if the trend in the data is linear or not. The wave around Lowess curves represents the level of confidence of the data points (the narrower the interval the better, less variability = more accuracy).
\marginnote{\small\color{blue}$\Lsh$Points=iterations. With less iterations comes high variability of the curve}[0cm]
<<nodes_modules_summary>>=

read.table("./data/modules.summary.104795.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)


@ 

\subsection{Network analysis for Spearman-related correlations (relaxed)}
\label{subsec:spearman}
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\begin{itemize}
\item \textbf{Average Expression}: 5
\item \textbf{Adjusted P-value}: equal or less than 0.045
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 1.5
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_spearman,out.width='5in'>>=

read.table("./data/networks.summary.104859.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_spearman>>=

read.table("./data/modules.summary.104859.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_spearman,out.width='5in'>>=

read.table("./data/networks.summary.114018.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_spearman>>=

read.table("./data/modules.summary.114018.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 


\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coospearmanstringent}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<coo_prediction_networks_summary_spearman,out.width='5in'>>=

read.table("./data/networks.summary.114017.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_spearman>>=

read.table("./data/modules.summary.114017.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\subsection{Network analysis for Pearson-related correlations (relaxed)}
\label{subsec:pearson}
\marginnote{\small\color{blue}$\Lsh$With pearson, we can only raise the data to power 10. All are discarded after 10.}[0cm]
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\begin{itemize}
\item \textbf{Average Expression}: 5
\item \textbf{Adjusted P-value}: equal or less than 0.045
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 1.5
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_pearson,out.width='5in'>>=

read.table("./data/networks.summary.104862.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 

\marginnote{\small\color{blue}$\Lsh$Since Lowess ranks by confidence, Log transformation seems the best, ie, low variability. For this, Log is removed from further tests.}[0cm]
Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_pearson>>=

read.table("./data/modules.summary.104862.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 

\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapse}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_pearson,out.width='5in'>>=

read.table("./data/networks.summary.104863.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_pearson>>=

read.table("./data/modules.summary.104863.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 

\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coo}
Genetic networks from differentially expressed genes selected by comparing sample cases with cell of origin classification based on ABC or GCB subtypes.
<<coo_prediction_networks_summary_pearson,out.width='5in'>>=

read.table("./data/networks.summary.104864.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 



Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_pearson>>=

read.table("./data/modules.summary.104864.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 





\subsection{Network analysis for Spearman-related correlations (stringent)}
\label{subsec:spearman}
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\marginnote{\small\color{blue}$\Lsh$Same analysis with more stringent parameters}[0cm]
\begin{itemize}
\item \textbf{Average Expression}: 10
\item \textbf{Adjusted P-value}: equal or less than 0.030
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 2
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}
Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_spearman_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119759.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_spearman_stringent>>=

read.table("./data/modules.summary.119759.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_spearman_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119760.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_spearman_stringent>>=

read.table("./data/modules.summary.119760.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:relapsespearman}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<coo_prediction_networks_summary_spearman_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119758.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))

@ 


Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_spearman_stringent>>=

read.table("./data/modules.summary.119758.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\subsection{Network analysis for Pearson-related correlations (stringent)}
\label{subsec:pearson}
Thresholds based on the Empirical Bayes approach to rank genes and determine if a gene is significantly expressed. Limma implementation.
\marginnote{\small\color{blue}$\Lsh$Same analysis with more stringent parameters}[0cm]
\begin{itemize}
\item \textbf{Average Expression}: 10
\item \textbf{Adjusted P-value}: equal or less than 0.030
\item \textbf{Log Fold Change}: 1
\item \textbf{B-statisitcs}: 2
\end{itemize}


\subsubsection{Nodal versus extra-nodal lymphoma}
\label{subsec:nodal}

Genetic networks from differentially expressed genes selected by comparing sample cases with nodal and extranodal lymphoma.
<<nodes_networks_summary_pearson_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119755.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 

Showing the number of modules per network and the number of genes per module. 
<<nodes_modules_summary_pearson_stringent>>=

read.table("./data/modules.summary.119755.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 

\subsubsection{Relapsed versus no CNS relapsed cases}
\label{subsec:relapse}
Genetic networks from differentially expressed genes selected by comparing sample cases with systemic or no CNS relapse lymphoma.
<<relapse_networks_summary_pearson_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119754.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 


Showing the number of modules per network and the number of genes per module. 
<<relapse_modules_summary_pearson_stringent>>=

read.table("./data/modules.summary.119754.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 

\subsubsection{Lymphoma cases classified by Cell-of-origin subtypes}
\label{subsec:coo}
Genetic networks from differentially expressed genes selected by comparing sample cases with cell of origin classification based on ABC or GCB subtypes.
<<coo_prediction_networks_summary_pearson_stringent,out.width='5in'>>=

read.table("./data/networks.summary.119757.txt", header = TRUE) %>% 
    ggplot(aes(
        x = MaxEdgesPerGene,
        y = NbNodes,
        fill = Standardization)) +
    theme_bw() +
    geom_step(aes(color = Standardization),
              stat = "identity") +
    facet_wrap( ~ CorrelationPower,
               ncol = 2,
               scales = "free") + 
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of potential connections per gene",
         y = "Number of genes per Network") +
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank"))


@ 



Showing the number of modules per network and the number of genes per module. 
<<coo_prediction_modules_summary_pearson_stringent>>=

read.table("./data/modules.summary.119757.txt", header = TRUE) %>%
    ggplot(aes(
        x = NbModules,
        y = MaxGenesPerModule,
        fill = Standardization)) +
    theme_bw() +
    geom_point(aes(shape = Standardization)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(x = "Number of modules per network",
         y = "Number of genes per module") +
    facet_wrap( ~ Standardization,
               ncol = 2,
               scales = "free") + 
    theme(legend.position = "top",
          strip.background = element_rect(linetype = "blank", 
                                          fill = "white"),
          panel.border = element_rect(linetype = "blank", 
                                      fill = NA),
          panel.grid.major = element_line(linetype = "blank")) +
    geom_smooth(method = 'loess', size = .5, level = 0.5, alpha=1)

@ 



\section{Machine Learning}
\label{sec:machinelearning}
Machine learning models were used for classification of patients cases into systemic relapse of DLBCL, CNS relapse or no relapse. Data are gene expression from Affymetrix arrays of 240 patients with a form of DLBCL. Subsets of the whole number of microarray probes will be used for classification.

\subsection{Regularization}
\label{subsec:regularization}
Least absolute shrinkage and selection operator (LASSO) was used for dimension reduction. Gene expression profiles were extracted from networks with significant connectivity. Subset selection using lasso, penalizes genes based on coefficient estimates, to increase accuracy of classification.

\subsubsection{Uncertainty estimation for selected genes from expression networks}
\label{subsec:uncertainty}
Plot showing, across a range of iterations, the mean probabilities of a subset of genes to correctly predict a patient case, or the certainty of a subset to estimate a correct classification. Briefly, cases are assigned to either diagnosis category, systemic relapse (SYST), CNS relapse (CNS), and no relapse (NOREL). During each iteration, a prediction is made to assign a category. Then a probability is calculated for having an accuracy performance for that iteration. A single iteration has a different random seed, which generates a different set of lambda coefficients for adjusting the lasso penalty. The best lambda across a grid of coefficients with the best accuracy classification is then selected based on accuracy. Adjusting the lambda score also adjusts the subset of genes used for the classification. For one best lambda there is one subset of significantly expressed genes and each gene has a different probability. For one best lambda there is one mean probability registered for that subset of genes.
\marginnote{\small\color{blue}$\Lsh$If a subset has 50 genes, the reported probabilities are the mean of each gene individual probability to predict all patient cases}[0cm]
<<boxplot_probabilities_lambda>>=
read.table("./data/summary.lambda.iterations20.multinomial.probabilities.txt", 
           row.names = 1, header = T) %>%
    ggplot(aes(x = class,
               y = probabilityScore,
               fill = class)) +
    theme_bw() +
    geom_boxplot() +
    geom_jitter(width = .2)
@ 

Plot showing the accuracy of assigning a patient to its correct class (or diagnosis) based on lambda calculation for lasso regularization. Each facet represents an accuracy for multiple iterations with a specific number of genes.
<<boxplot_accuracies_lambda,out.width='4in',out.height='2in'>>=
df <- read.table("./data/summary.lambda.iterations20.multinomial.accuracies.txt", 
                 row.names = 1, header = T)
mir <- min(df$regNgenes)
mar <- max(df$regNgenes)
q1 <- floor((mir+mar)/2.5)
q2 <- floor((mir+mar)/1.75)
df$grouped <- cut(df$regNgenes, c(0, q1, q2, mar))
levels(df$grouped) <- c(paste0(0,"-",q1), 
                        paste0(q1+1,"-",q2), 
                        paste0(q2+1,"-",mar))
df %>%
    ggplot(aes(x = group,
               y = accuracy,
               fill = group)) +
    geom_violin(trim = FALSE) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    labs(x = "Different diagnosis for patients with DLBCL",
         y = "Accuracy scores for multiple iterations of classification") +
    facet_wrap( ~ grouped,
               ncol = 3,
               scales = "free") + 
    theme(legend.position = "top")


@ 

\subsection{Models selected for classification}
\label{subsec:models}

\marginnote{\small\color{blue}$\Lsh$ Parameters are crucial to optimize for accuracy. Similar models have different parameters}[0cm]

\begin{table}[!h]
  % \captionsetup{format=plain,justification=centerlast}
  \caption{\bf Machine learning models}
  \renewcommand{\arraystretch}{0.8}
   \small\addtolength{\tabcolsep}{-2pt}
  \begin{tabular}{p{.45cm} p{6.5cm} l p{4cm} l}
    \toprule
    
    \# & Model & R package$^*$ & Parameters & Abbreviation \\
    
    \midrule

    1 & Naive bayes & naivebayes & laplace, usekernel, adjust & naive\_bayes \\
    2 & Weighted k-Nearest Neighbors & kknn & kmax, distance, kernel & kknn \\
    3 & Penalized multinomial regression & nnet & decay & multinom \\
    4 & C5.0 & C50 & trials, model, winnow & C5.0 \\
    5 & Random forest & randomForest & mtry & rf \\
    6 & Regularized random forest & RRF & mtry, coefReg, coefImp & RRF \\
    7 & Linear discriminant analysis (LDA) & MASS & dimen & lda2 \\
    8 & Localized LDA & klaR & k & loclda \\
    9 & Flexible discriminant analysis (FDA) & mda & degree, nprune & fda \\
    10 & Bagged FDA & mda & degree, nprune & bagFDA \\
    11 & Bagged FDA using gCV pruning & earth & degree & bagFDAGCV \\
    12 & Penalized discriminant analysis & mda & lambda & pda \\
    13 & Partial least squares & pls & ncomp & kernelpls \\
    14 & Support vector machines (SVM) with linear kernel & kernlab & C & svmLinear \\
    15 & L2 regularized SVM (dual) with linear kernel & LiblineaR & cost, loss & svmLinear3 \\
    16 & SVM with polynomial kernel & kernlab & degree, scale, C & svmPoly \\
    17 & SVM with radial basis function kernel & kernlab & sigma, C & svmRadialSigma \\
    18 & Neural network (NN) & nnet & size, decay & nnet \\
    19 & Monotone multi-layer perceptron NN & monmlp & hidden1, n.ensemble & monmlp \\
    20 & Stacked autoencoder deep NN & deepnet & layer1, layer2, layer3, hidden\_dropout, visible\_dropout & dnn \\
    21 & Boosted logistic regression & caTools & nlter & LogitBoost \\
    22 & Regularized logistic regression & LiblineaR & cost, loss, epsilon & regLogistic \\
    23 & Stochastic gradient boosting & gbm & n.trees, interaction.depth, shrinkage, n.minobsinnode & gbm \\

    \bottomrule
  \end{tabular}
  \vspace{-10pt}
  \caption*{$^*$ The version of each package is shared at section \ref{subsec:version}.}
  \label{tab:models}
\end{table}


\subsection{Machine learning performance benchmarks}
\label{subsec:benchmarks}
Please follow up on performance metrics for classification problem by reading \href{http://rali.iro.umontreal.ca/rali/sites/default/files/publis/SokolovaLapalme-JIPM09.pdf}{Sokolova 2009}.
\marginnote{\small\color{blue}$\Lsh$ \href{https://scaryscientist.blogspot.com/2016/03/confusion-matrix.html}{Link} to metrics definitions}[0cm]
\begin{itemize}
\item \textbf{Sensitivity}, is how many true cases are correctly classified to their expected class. Or \textbf{recall} (math), is the fraction of events where we correctly declared \textit{i} form all cases where the true of state of the world is \textit{i}. $TP / (TP + FN)$
\item \textbf{Specificity}, is how many wrong cases are correctly classified elsewhere. $TN / (TN + FP)$
\item \textbf{Precision} (math), is the fraction of events where we correctly declared \textit{i} out of all instances where the algorithm declared \textit{i}. $TP / (TP + FP)$
\item \textbf{Accuracy}, is an overall measure that assesses the predictive model by comparing predicted classes to observed expected classes. $(TN + TP) / (TP + TN + FP + FN)$
  \end{itemize}

\subsubsection{Creating the baseline of models performance}
\label{subsec:baseline}
\marginnote{\small\color{blue}$\Lsh$ Precision and recall are best for multi class learning}[0cm]
Machine learning models were trained only without tuning for hyperparameter optimization. Metrics generated show the raw performance of each model.\\

For this type of nominal data, classification models (not regression) are used, see Section /ref{subsec:models}. The performance metrics for this type of models are an accuracy score and kappa, which takes into account the possibility of the agreement occurring by chance (the kappa score however reflects the adequate agreement). Standard error ({\color{red}SE in red}) bars for the kappa significance per model reproducible across 10 cross-validation each repeated 5 times. Minimum and maximum accuracy thresholds are held at 95\% confidence intervals.\\
\marginnote{\small\color{blue}$\Lsh$ Kappa is Cohen’s (unweighted) Kappa statistic averaged across the resampling results}[0cm]


Load standard error and deviation equations.
<<summary_function>>=
summary_SE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {

    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }
    datac <- ddply(data, groupvars, .drop=.drop,
                   .fun= function(xx, col, na.rm) {
                       c( N    = length2(xx[,col], na.rm=na.rm),
                         mean = mean   (xx[,col], na.rm=na.rm),
                         sd   = sd     (xx[,col], na.rm=na.rm)
                         )
                   },
                   measurevar,
                   na.rm
                   )
    datac <- rename(datac, c("mean"=measurevar))
    # Calculate standard error of the mean
    datac$se <- datac$sd / sqrt(datac$N) 
    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval:
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult
    return(datac)
}

@ 

Metrics for classification performance without tuning for hyperparameter optimization. Quick comparison of statistical learning on the DLBCL data.
\marginnote{\small\color{blue}$\Lsh$ Accuracy is the true prediction rate averaged over cross-validation iterations}[0cm]
<<bar_performance_ml_metrics,out.width='5in'>>=
accuracy <- read.table("./data/Accuracy.metrics.txt", header = TRUE)
kappa <- read.table("./data/Kappa.metrics.txt", header = TRUE)

accuracy.se <- summary_SE(accuracy, measurevar = "Mean", groupvars = "model")
kappa.se <- summary_SE(kappa, measurevar = "Mean", groupvars = "model")

accuracy.se %>% 
    ggplot(aes(x = model,
               y = Mean)) +
    geom_bar(position=position_dodge(), 
             stat="identity") +
    geom_errorbar(data = accuracy.se,
                  aes(ymin=Mean-se, 
                      ymax=Mean+se),
                  width=.3,
                  position=position_dodge(.9)) +
    geom_line(data = kappa.se,
              aes(x = as.numeric(model),
                  y = Mean),
              color = "red") +
    geom_point(data = kappa.se,
               size=2, shape=21, fill="red") +
    geom_errorbar(data = kappa.se,
                  aes(ymin=Mean-se, 
                      ymax=Mean+se),
                  width=.25,
                  position=position_dodge(.9),
                  color = "white") +
    theme_minimal() +
    ylab("Mean of accuracy across 10 CV resampled 10 times/iteration (Total 10 iterations)") +
    xlab("Machine Learning models iterated for 10 rounds") +
    theme(legend.position = "top") + 
    guides(fill=guide_legend(title="Number of parameters per model")) +
    scale_fill_brewer(palette = "Dark2") +        
    theme(axis.text.x = element_text(vjust = .5,
                                     angle = 45,
                                     size = 8))

@ 

Kappa (vertical axis) and accuracy (horizontal axis) calculated from the performance tests of machine learning models. The higher kappa is the stronger agreement for a prediction and classification.
<<scatterplot_performance_ml_metrics>>=
data.frame(accuracy, kappa) %>% 
    ggplot(aes(x = Mean,
               y = Mean.1,
               fill = model)) + 
    geom_point(size=2, shape=21) +
    theme_minimal() +
    ylab("Mean of Kappa with adequate probability agreement") +
    xlab("Mean of accuracy with overall perdiction certainty") +
    theme(legend.position = "top")
@ 

Maximum accuracy registered for machine learning fitting for all classification groups. Iterations for reproducibility were executed 10 times.
<<boxplot_maximum_performance_ml_metrics,out.width='5in'>>=
read.table("./data/Accuracy.metrics.txt", header = TRUE) %>% 
    ggplot(aes(x = reorder(model, Max.),
               y = Max.,
               fill = as.character(parameters))) +
    geom_boxplot() +
    geom_jitter(shape=16, position=position_jitter(0.2), cex = 1.5) +
    coord_flip() +
    scale_fill_brewer(palette = "Dark2") +
    theme_minimal() +
    ylab("Maximum accuracy across 10 CV resampled 10 times/iteration (Total 10 iterations)") +
    xlab("Machine Learning models iterated 10 rounds") +
    theme(legend.position = "top") + 
    guides(fill=guide_legend(title="Number of parameters per model"))

@ 



\subsubsection{Models performance with hyperparameter tuning}
\label{subsec:tuning}
Compared to the baseline, the parameters available for each learner should increase its performance at predicting each expected outcome. Tuning these hyperparameters will leverage the results with increased accuracy.\\

\subsubsection{Classifiers accuracy at optimal parameters}
\label{subsec:optimal}
Final report of the actual accuracy for each machine learning model from comparing predicted values and expected outcomes.\\
\marginnote{\small\color{blue}$\Lsh$ Data are retrieved from Confusion Matrix}[0cm]

How long (seconds) a statistical learner requires to optimize the hyperparameters and gets the highest significant accuracy on expected data.
<<bar_duration_performance>>=
df <- read.table("./data/log.performance3.full.hyperTuning.seed9793582.txt", header=T)
df$group <- gsub("[0-9]", "", df$group)

df %>%
    ggplot(aes(x = reorder(model, durationSeconds),
               y = durationSeconds)) +
    geom_bar(position = position_dodge(),
             stat = "identity") +
    coord_flip() +
    theme_minimal() +
    ylab("Machine learners") +
    xlab("Time (seconds) for tuning and optimizing precision/recall")

@ 

How is time training a model deliver on the significance of its accuracy? The p-value evaluates whether the overall accuracy rate is greater than the rate of the largest class. Proportions between classes (if one group of samples is larger than an other) is also considered in the hypothesis testing.

\marginnote{\small\color{blue}$\Lsh$ \href{https://topepo.github.io/caret/measuring-performance.html}{Link} documentation Section 17.2}[0cm]

<<scatterplot_duration_performance>>=
df %>%
    ggplot(aes(y = accuracyPval,
               x= durationSeconds,
               fill = as.character(model))) +
    geom_point(size = 2,
               shape = 21) +
    theme_minimal() +
    xlab("Time (seconds) for tuning and optimizing precision/recall") +
    ylab("P-value between correct prediction and no-information classification") +
    theme(legend.position = "top")    
               
@ 

Precision versus recall across all sample groups for a multi-class classification.
\marginnote{\small\color{blue}$\Lsh$True/False Positives/Negatives}[0cm]
<<scatterplot_precisionRecall_performance>>=
df %>%
    ggplot(aes(x = Precision,
               y = Recall,
               group = as.character(group),
               na.rm = T)) +
    geom_point(aes(size = 2,
               shape = group,
               color = model)) +
    theme_minimal() +
    xlab("Precision of how many correct classes were called") +
    ylab("Recall/Sensitivity") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.position = "top")               

@ 


Specificity and sensitivity across all sample groups.
<<scatterplot_sepecificitySensitivity_performance>>=

df %>%
    ggplot(aes(x = Sensitivity,
               y = Specificity,
               group = as.character(group))) +
    geom_point(aes(size = 2,
               shape = group,
               color = model)) +
    theme_minimal() +
    xlab("Sensitivity or true positive rate") +
    ylab("Specificity or true negative rate") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.position = "top")               

@ 


Accuracy and Kappa across all sample groups.
<<scatterplot_accuracyKappa_performance>>=

df %>%
    ggplot(aes(x = accuracy,
               y = kappa)) +
    geom_point(aes(size = 2,
               color = model)) +
    theme_minimal() +
    xlab("Accuracy") +
    ylab("Kappa on how well the classifier performed compared to chance") +
    theme(legend.position = "top")               

@ 


Accuracy versus the p-value of each classification. The p-value is a hypothesis test between predicting expected samples and the probability that the classification is biased by disproportionate class sizes (one group of samples is larger than an other).
<<scatterplot_doubleaccuracyPval_performance>>=

df %>%
    ggplot(aes(x = accuracy,
               y = accuracyPval)) +
    geom_point(aes(size = 2,
               color = model)) +
    theme_minimal() +
    xlab("Accuracy") +
    ylab("P-value between correct prediction and false no-information classification") +
    theme(legend.position = "top")               

@ 


Prevalence of cases for each classifier. Were the classes perfectly balanced? A positive predictive score is similar to precision while accounting for disproportionality of the classes.
<<bar_prevalence_performance>>=
df %>%
    ggplot(aes(x = Balanced.Accuracy,
               y = Detection.Prevalence,
               group = as.character(group))) +
    geom_point(aes(size = 2,
               color = model,
               shape = group)) +
    theme_minimal() +
    xlab("Accuracy") +
    ylab("Prevalence") +
    theme(legend.position = "top")               
    
@ 







\subsection{Version of machine learning models}
\label{subsec:version}
\marginnote{\small\color{blue}$\Lsh$ Version of R packages used for their algorithmic implementation of machine learning models}[0cm]







\section{System Information}
\label{sec:sys_info}
\noindent
The version number of R and packages loaded for generating the vignette were:
<<sessionInfo>>=
###save(list=ls(pattern=".*|.*"),file="PD.Rdata")
sessionInfo()
@ 



\end{linenumbers}
\end{document}
