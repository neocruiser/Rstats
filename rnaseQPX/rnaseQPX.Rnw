
\documentclass[9pt,english]{extarticle}
\include{canevas_config}

\begin{document}
\author{Sleiman Bassim}
\title{R implementation}
\maketitle
\begin{linenumbers}
<<setup, include=FALSE, cache=FALSE>>=
# set global chunk options
opts_chunk$set(dev="postscript",
               fig.path="graphics/plot",
               fig.lp= "",
               comment=NA,
               fig.keep="high",
               fig.show='hold',
               fig.align='center', 
               out.width='.49\\textwidth',
               tidy.source=TRUE,
               crop=TRUE,
               results="markup",
               warnings=FALSE,
               error=FALSE,
               message=FALSE)
options(formatR.arrow=TRUE,
        width=70,
        digits = 3,
        scipen = 6)
@ 

\noindent
\marginnote{\small\color{blue}$\Lsh$ Project started April 2015 - ended June 2015}[.1cm]

Loaded functions:
<<loading,results='hide'>>=
#source("/media/Data/Dropbox/humanR/01funcs.R")
rm(list=ls())
@ 

Load packages.
<<pack,results='hide'>>=
pkgs <- c('xlsx','lattice','latticeExtra',
          'ggplot2', 'dplyr', 'vegan', 'tidyr',
          'ggbiplot')
lapply(pkgs, require, character.only = TRUE)
@

\section{Show the length distribution of reads}
\label{sec:distribution}

Load \textit{gff3} sequence length data for mapped QPX libraries and references.
GFF3 files contain the sequence length of each contig. These contigs belong to Steve Roberts \textbf{genome v015 and 017} and \textbf{transcriptome v21} of QPX. 


\marginnote{\small\color{blue}$\Lsh$ Refer to github front page of the rnaseQPX project}[.1cm]
<<load>>=
genome <- read.table("./data/QPX_Genome_v017.gff3")
head(genome)
transcriptome <- read.table("./data/QPX_transcriptome_v2orf.gff3")
@ 

GFF3 counts of MME transcriptomes \textbf{MMETSP0098} and \textbf{MMETSP00992}, and the custom assembly with MMETSP0098.
<<load2>>=
mme98 <- read.table("./data/MMETSP0098.gff3")
mme99 <- read.table("./data/MMETSP0099_2.gff3")
mme98c <- read.table("./data/mme98cust.gff3")
genomv015 <- read.table("./data/QPX_v015.gff3")
@ 

The number of bases has been counted and published elsewhere by the authors who assembled the references and sequenced the QPX libraries. Working through their data, we provide a distribution of contig length for genome of Steve's QPX. The purpose of this analysis is to identify 2 things:
\begin{itemize}
\item Biases in contig length
\item Comparison of parameters used for assembling the references
\end{itemize}
<<distribution>>=
histogram(~ (genome$V5), 
          type= 'count',
          nint = 75,
          data = genome,
          xlab = 'Sequence length (bp)',
          ylab = 'Nb of contigs (555 total)',
          col = 'red')
@ 

Distribution of Steve's QPX transcriptome.
<<distribution2>>=
histogram(~ transcriptome$V5,
          type = 'count',
          col = 'red',
          data = transcriptome,
          nint = 75,
          xlab = 'Sequence length (bp)',
          ylab = 'Nb of contigs (11774 total)')
@ 

Distribution of length of MMETSP0098.
<<distrinutiuon3>>=
histogram(~ mme98$V5,
          type = 'count',
          nint = 75,
          data = mme98,
          xlab = 'Sequence length (bp)',
          ylab = 'Nb of contigs (11774 total)')
@ 

Superpose the length of contigs in:
\begin{itemize}
\item Steve's genome v017 (555 contigs)
\item Steve's transcriptome
\item MMEtsp0098 transcriptome
\item MMEtsp00992 transcriptome
\item MMEtsp0098 custom transcriptome
\item Steve's Genome v015 (approx 22,000 contigs)
\end{itemize}

Merge datasets.
\marginnote{\small\color{blue}$\Lsh$ Assign a new column to identify contigs.}[.1cm]
<<data3>>=
grouping <- rbind(genome[, c(1,5)],
                  transcriptome[, c(1, 5)],
                  mme98[, c(1,5)],
                  mme99[, c(1,5)],
                  mme98c[, c(1,5)],
                  genomv015[, c(1,5)])
grouping <- data.frame(grouping,
                       y = c(rep("GenomeV17", nrow(genome)),
                           rep("TrxV22", nrow(transcriptome)),
                           rep("MME98", nrow(mme98)),
                           rep("MME99", nrow(mme99)),
                           rep("MME98custom", nrow(mme98c)),
                             rep("(GenomeV15)", nrow(genomv015))))

dim(grouping)
@ 

Plot reads length of the 6 assemblies including 2 QPX genomes.
\marginnote{\small\color{blue}$\Lsh$ A higher resolution of this chart can be found in the Supplemental Information}[.1cm]
<<summaryPlot1>>=
custom.colors <- c(col1 = "#762a83", 
                   col2 = "#1b7837", 
                   col3 = "#ef8a62",
                   col4 = "#2166ac",
                   col5 = "#8c510a",
                   col6 = "#e6ab02")

histogram( V1 ~ V5,
     data = grouping,
     nint = 55,
     scales = list(log = 10),
     type = "p",
     #breaks = seq(4,8,by=0.2),
     ylim = c(0,28),
     groups = grouping$y,
     panel = function(...) panel.superpose(..., 
         panel.groups = panel.histogram,
         col = custom.colors, 
         alpha = 1),
     auto.key=list(columns=3,
         rectangles = FALSE,
         col = custom.colors),
     main = 'Different QPX assemblies and the length of their contigs',
     xlab = 'Length of all contigs',
     ylab = 'Percentage of the total assembly (count)'
     )

@ 


\section{Calling SNPs: Testing tools, parameters, and filters}
\label{sec:snps}
SNPs were called either with samtools \textit{mpileup} function and the highest significant were selected with bcftools or they have been called with GATK. Either way SNP calling was done on each QPX library separately. QPX libraries were:
\begin{itemize}
\item mmetsp0098 from New York
\item mmetsp001433 from New York
\item mmetsp00992 from Massachusetts
\item mmetsp001002 from Virginia
\item mmetsp0099 from Massachusetts
\item mmetsp00100 from Virginia
\end{itemize}

\subsection{Load data}
\label{subsec:loding3}
Number of SNPs called with either packages were counted. Calls were done after read duplicates were removed with Picard.
<<loadcc32>>=
counts.SNP <- read.xlsx("./data/snp.counts.xlsx", sheetIndex = 1)
glimpse(counts.SNP)
@ 

Histogram grouped by QPX library showing difference in SNPs counts relative to the reference used for mapping and the number of times GATK has been used to recalibrate calls.
GATK (x1, x2, x3) represent one, two or three rounds of recalibration. The recalibration is done over a list of variants called under stringent parameters. SR: Steve Roberts genomes. Cust: custom assembly of mmetsp0098.

\marginnote{\small\color{blue}$\Lsh$ Recalibration is done with GATK. The strategy is described in the pipeline on github \href{https://goo.gl/kYZJua}{here}.}[.1cm]
<<hist1234>>=
xyplot( factor(reference) ~ as.matrix(counts) | factor(sample),
       data = counts.SNP[-c(1:24), ],
       groups = counts.SNP$reference,
       pch = 21,
       cex = 1,
       type = c("p"),
       xlab = 'Number of SNPs called',
       ylab = 'References & GATK filters')
@ 

Plot the difference between QPX libraries and variant calling packages for the number of called SNPs. 
Combined: an assembly made of the combination of mmetsp0098, 992, 1002, 1433. SR: Steve Roberts genomes and transcriptomes (15 and 21 respectively). Samtools was done on trxSRv21rmdup.
<<called123>>=
ggplot(counts.SNP,
       aes(x = factor(sample),
           y = counts,
           fill = factor(reference))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() +
    labs(title = "SNP counts between GATK and samtools with 6 references",
         x = "QPX Libraries",
         y = "SNP count")
@ 

Another plot for cluster analysis between references and SNPs called. I find this useful for a fast check of outliers and errors in importing data. In \textit{comG3} com=combined assembly, G=genome reference, 3= x3 recalibration rounds.
<<barplot11>>=
dat <- read.xlsx("./data/snp.counts.xlsx", sheetIndex = 4)
custom.colors <- c(col1 = "#b2182b",
                   col2 = "#ef8a62",
                   col3 = "#fddbc7",
                   col4 = "#e0e0e0",
                   col5 = "#999999",
                   col6 = "#4d4d4d")
barplot((as.matrix(dat[, -c(1:5)])),
        col = custom.colors,
        horiz = TRUE,
        las = 2,
        beside = T,
        legend.text = factor(dat[, 1]),
        cex.names = .7,
        xlab = '(log10) Number of SNPs called',
        ylab = 'References')
@ 



Plotting only the GATK called SNPs.
<<gatk12>>=
counts.SNP <- counts.SNP[-c(1:24), ]
ggplot(counts.SNP,
       aes(x = factor(sample),
           y = counts,
           fill = factor(reference))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() +
    labs(x = "QPX Libraries",
         y = "SNP counts")
@ 


Plot the difference between the number of SNPs called on the 6 QPX libraries using either the assembled or custom assembled mmetsp0098 reference. Also show the variation pattern with the number of reads used for calling SNPs. First, prepare SNP data.
<<diffreferences98>>=
x1 <- counts.SNP[counts.SNP$reference %in% "mmetsp0098GATKx1", ]
x2 <- counts.SNP[counts.SNP$reference %in% "mmetsp0098CustGATKx1", ]
@ 

Next, add the number of reads per QPX library. This is the count of non duplicate reads that mapped to each of all the references used.

<<refreads>>=
ref.reads <- read.xlsx("./data/refreads.xlsx", sheetIndex = 1)
head(ref.reads)
y <- ref.reads[1:12, ]
@ 

Plot difference.
\marginnote{\small\color{blue}$\Lsh$ A higher resolution chart of this analysis can be found in the Supplemental Information}[.1cm]
<<differenceplotting, out.width='.49\\linewidth', fig.show='hold'>>=
dat <- data.frame(rbind(x1, x2), reads = y$counts)

ggplot(dat,
       aes(x = factor(sample),
           y = counts,
           fill = factor(reference))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() +
    labs(x = "QPX Libraries",
         y = "SNP counts")

ggplot(dat,
       aes(x = factor(sample),
           y = reads,
           group = factor(reference))) +
    geom_line(size = .2)+
        geom_point(data = dat,
                   aes(x = factor(sample),
                       y = reads,
                       colour = factor(reference),
                       size = counts)) +
        theme_bw() +
        labs(x = "QPX Libraries",
             y = "Mapped reads counts")
@ 

Plot number of all mapped reads for each QPX library and for all 4 references.
<<readsprecall>>=
ggplot(ref.reads,
       aes(x = factor(sample),
           y = counts, 
           group = factor(reference))) + 
    geom_line(size = .2) + 
        geom_point(aes(shape = factor(reference))) + 
            theme_bw() + 
        labs(x = "QPX libraries",
             y = "Read counts")
@ 

Difference in SNPs called between the already assembled and the custom assembled \textit{mmetsp0098} reference.
\marginnote{\small\color{blue}$\Lsh$ The custom assembled mmetsp0098 was done with trinity}[.1cm]
<<mmetsp0098ref>>=
dat <- read.xlsx("./data/snp.counts.xlsx", sheetIndex = 2)
ggplot(dat,
       aes(x = factor(sample),
           y = counts,
           fill = factor(reference))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() + 
    labs(x = "QPX libraries",
         y = "SNP counts")
@ 

Another way to show difference between GATK recalibration protocols and the way this strategy decreases the number of SNPs called by readjusting of nucleotide probabilities for each read. The plot shows also the difference in SNP called between mmetsp0098 custom (the first 3 bars) and original (the last 3 bars) assemblies.
<<barplotGATK>>=
dat <- read.xlsx("./data/snp.counts.xlsx", sheetIndex = 3)
custom.colors <- c(col1 = "#b2182b",
                   col2 = "#ef8a62",
                   col3 = "#fddbc7",
                   col4 = "#e0e0e0",
                   col5 = "#999999",
                   col6 = "#4d4d4d")

barplot(as.matrix(dat[, -1]),
        horiz = TRUE,
        col = custom.colors,
        xlab = "Difference in number of called SNPs between references",
        ylab = 'Difference in GATK filtering protocols',
        las = 2,
        legend = dat$sample)
@ 

\section{Final filtering}
\label{subsec:ffilter}
GATK hard filtering removes SNPs with low quality or confidence. This is calculated relatively to the depth of coverage. Using 3 three different thresholds for \textit{QD} (qualtiy of depth) we get the number of SNPs that pass the filters. 

\begin{equation}
  \label{eq:1}
  QD = \frac{Confidence}{DepthCoverage}
\end{equation}

\begin{equation}
  \label{eq:2}
  DepthOfCoverage = \frac{NbOfReads \times ReadLength}{AssemblySize}
\end{equation}


\subsection{Working with the combined assembly and genome v15}
\label{sec:combined}
Difference in called SNPs between QPX libraries mapped to 2 different references, the combined assembly (represented by lower bar labels) and the genome v15 of S. Roberts (represented by higher bar labels). \textit{A higher resolution bar can be found in Supplemental Information}.
\marginnote{\small\color{blue}$\Lsh$ \textbf{Genome v15 S. Roberts} is used in the remaining tests}[.1cm]
<<snphardfilter>>=
dat <- read.xlsx("./data/hard.snps.xlsx", sheetIndex = 1)
ggplot(dat,
       aes(x = factor(sample),
           y = snps,
           fill = factor(qd)
#           group = factor(reference)
           )) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() + 
            geom_text(aes(x = factor(sample), 
                          y = snps, 
                          ymax = snps, 
                          label = snps,
                          size = 2,
                          hjust = 1),
                      position = position_dodge(width=1)) +
                    coord_flip() + 
                        scale_fill_brewer() +
                    labs(x = "Count of SNPs ref:combined (lower) and ref:genome15 (higher)",
                         y = "QPX libraries")
@ 

Number of SNPs per strain at \textit{QD = 5}. SNPs called against \textit{SR genome v15}. The number of reads (approx 100 nt in size) per library has been counted and plotted previously, the data is in \textit{refreads.xlsx}.
<<snphardfilter2>>=
dat <- read.xlsx("./data/hard.snps.xlsx", sheetIndex = 1)
dat <- dat[7:10, 1:2]
dat$Treads <- ref.reads[c(19, 22, 20, 21), 2]
dat$norm <- with(dat, (snps/Treads)*1000)

ggplot(dat,
       aes(x = as.factor(sample),
           y = norm)) +
    geom_bar(stat = "identity") + 
        geom_text(aes(x = as.factor(sample),
                      y = norm,
                      ymax = norm,
                      label = round(norm, digits = 2),
                      color = "white",
                      vjust = 2,
                      size = 3)) +
        labs(x = "QPX libraries",
             y = "Normalized count of nb of SNPs/nb of reads")
@ 


We can also do the same thing with indels.
<<indelhardfilter>>=
dat <- read.xlsx("./data/hard.snps.xlsx", sheetIndex = 1)
ggplot(dat,
       aes(x = factor(sample),
           y = indels,
           fill = factor(qd))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() + 
            geom_text(aes(x = factor(sample), 
                          y = indels, 
                          ymax = indels, 
                          label = indels,
                          size = 2,
                          hjust = 1),
                      position = position_dodge(width=1)) +
                    coord_flip() + 
                        scale_fill_hue(c = 40, l = 60) +
                    labs(x = "Count of indels ref:combined (lower), ref:genome15 (higher)",
                         y = "QPX libraries")
@ 

The combined assembly is already published. It is added here with the other references because it is heavily annotated and their contigs are extensively mapped. 
Load in new mapped data to the combined reference:
<<combined.loaded>>=
combined <- read.xlsx("./data/snp.counts.xlsx", sheetIndex = 1)
glimpse(combined)
@ 

Difference in SNPs called between the genome v15 of S. Roberts and the official combined assembly. First extract relative rows.
<<combined>>=
dev <- paste("genomSRv15GATKx", seq(1,3,1), sep = "")
ser <- paste("combinedGATKx", seq(1,3,1), sep = "")
difference <- rbind(combined[combined$reference %in% dev, ],
               combined[combined$reference %in% ser, ])

d.ref <- ref.reads[c(19:30), ]
@ 

Plot difference.

\marginnote{\small\color{blue}$\Lsh$ A higher resolution of this plot can be found in supplemental Information}[.1cm]
<<combined_diff1, out.width='.49\\linewidth', fig.show='hold'>>=
ggplot(difference,
       aes(x = factor(sample),
           y = counts,
           fill = factor(reference))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw()

ggplot(d.ref,
       aes(x = factor(sample),
           y = counts,
           group = factor(reference))) +
    geom_line(size = .2)+
        geom_point(data = d.ref,
                   aes(x = factor(sample),
                       y = counts,
                       colour = factor(reference),
                       size = counts)) +
        theme_bw()
@ 


\section{Descriptive stats of all processed libraries}
\label{sec:descriptive}
This following section shows the mean length of all sequences assembled from each library, the number of base pairs per library, the identified protein features from these sequences, and the number of functional enzymes identified by mapping to public libraries.
It is to note the number of predicted and identified rRNA features in each of these libraries is significantly low.
Regress different variables on each others for visualization purposes.
<<descriptive1>>=
stats <- read.xlsx("./data/libraries.xlsx", sheetIndex = 1)
rstats <- stats[complete.cases(stats), ]
#rownames(rstats) <-  stats[, 1]

# The whole new magical script
# job: order columns
# dependecies: dplyr
rstats <- within(rstats, 
                 libraries <- factor(libraries, 
                                     levels = arrange(rstats, 
                                         bp)$libraries))

ggplot(rstats,
       aes(x = libraries,
           y = bp)) + 
    geom_bar(stat = "identity") +
        theme_bw() + 
            coord_flip() +
                geom_text(aes(x = libraries,
                              y = bp,
                              ymax = bp,
                              label = bp,
                              size = 5,
                              color = "white",
                              hjust = 1.2)) +
                labs(x = "Number of base pair (nb) in the sequenced QPX libraries",
                     y = "QPX libraries")
@ 

The plot shows the difference between QPX libraries according to the number of base pair (bp x 1000, the identified protein features estimated from assembled sequences (feature), the functional sequences estimated from the contigs (function), the mean length of contigs in each library, and the number of contigs (sequence) assembled from raw reads after trimming and duplicate removal (all basic quality controls).

\marginnote{\small\color{blue}$\Lsh$ The number of base pair must be multiplied by 1000 in this chart}[.1cm]
<<descriptive3>>=
stats <- read.xlsx("./data/libraries.xlsx", sheetIndex = 1)
rstats <- stats[complete.cases(stats), ]
rstats$bp <- rstats$bp/1000
#rstats <- rename(rstats, bpx1000 = bp)
rstats <- gather(rstats, "feature", "count", c(2:4, 7:8))
ggplot(rstats, 
       aes(x = libraries,
           y = count,
           group = factor(feature))) + 
    geom_line(size = .2) +
        geom_point(aes(shape = factor(feature),
                       size = 1.5)) +
                       theme_bw() +
                           geom_text(aes(x = libraries,
                                         y = count,
                                         ymax = count,
                                         label = count,
                                         size = 1.5,
                                         hjust = ifelse(sign(count)>1, .5, 0)),
                                     position = position_dodge(width = 1)) +
                           labs(x = "QPX libraries",
                                y = "Counts")
@ 

Principal component analysis and diagnostics.
<<pca1>>=
stats <- read.xlsx("./data/libraries.xlsx", sheetIndex = 1)
rownames(stats) <- stats$libraries
rstats <- stats[complete.cases(stats), -1]
rstats <- decostand(rstats, method = "range")
p = princomp(~bp + mlength + sequence + rna
   , data= rstats)
summary(p)
biplot(p)
@ 
Finally a summary of all sequence data.
<<table_descriptive>>=
stats[, -1]
@ 


\section{Applied annotations, subsytem predictions, and taxonomic distribution}
\label{sec:applied}
Like the title implies, identified and predicted annotations and protein features are mapped to public sequence libraries.
\marginnote{\small\color{blue}$\Lsh$ This annotation has been done with MG-RAST. Visit \href{http://goo.gl/lXBURZ}{here} for a description of their fast annoation server}[.1cm]

Reshape data, transform columns into rows.
<<predicted1>>=
predicted <- read.xlsx("./data/libraries.xlsx", sheetIndex = 3)
predicted <- gather(predicted, "ko", "count", 3:8, na.rm = TRUE)
summary(predicted)
@ 

Plot difference in identified protein features between libraries.
<<predicted2>>=
ggplot(predicted,
       aes(x = lib,
           y = count,
           group = factor(ko))) + 
    geom_line(size = .2) +
        geom_point(aes(shape = factor(ko),
                       size = 1.5)) +
                       theme_bw() +
                           geom_text(aes(x = lib,
                                         y = count,
                                         ymax = count,
                                         label = count,
                                         size = 1.5,
                                         hjust = ifelse(sign(count)>1, .5, 0)),
                                     position = position_dodge(width = 1)) +
                           labs(x = "QPX libraries",
                                y = "Counts")
@ 

In this next snippet subsystems are discussed. \href{http://www.nmpdr.org/FIG/wiki/view.cgi/FIG/FunctionalCoupling}{Functional coupling and chromosomal clusters} are shown for \textit{clustering-based subsytems} among other subsytems.
<<predicted3>>=
predicted <- read.xlsx("./data/libraries.xlsx", sheetIndex = 4)
predicted <- gather(predicted, "subsystems", "count", 3:8, na.rm= TRUE)
ggplot(predicted,
       aes(x = lib,
           y = count,
           group = factor(subsystems))) + 
    geom_line(size = .2) +
        geom_point(aes(shape = factor(subsystems),
                       size = 1.5)) +
                       theme_bw() +
                           geom_text(aes(x = lib,
                                         y = count,
                                         ymax = count,
                                         label = count,
                                         size = 1.5,
                                         hjust = ifelse(sign(count)>1, .5, 0)),
                                     position = position_dodge(width = 1)) +
                           labs(x = "QPX libraries",
                                y = "Counts")
@ 

Finally, a taxonomic classification on sequence similarities gives insights on sequence relatedness or sample contamination. Five classes were selected, bacteria, fungi, algae, parasite, and bivalvia.
<<predicted4>>=
predicted <- read.xlsx("./data/libraries.xlsx", sheetIndex = 5)
predicted <- gather(predicted, "class", "count", c(3,5:9), na.rm = TRUE)
ggplot(predicted,
       aes(x = lib,
           y = count,
           group = factor(class))) + 
    geom_line(size = .2) +
        geom_point(aes(shape = factor(class),
                       size = 1.5)) +
                       theme_bw() +
                           geom_text(aes(x = lib,
                                         y = count,
                                         ymax = count,
                                         label = count,
                                         size = 1.5,
                                         hjust = ifelse(sign(count)>1, .5, 0)),
                                     position = position_dodge(width = 1)) +
                           labs(x = "QPX libraries",
                                y = "Counts")
@ 
\marginnote{\small\color{blue}$\Lsh$ A higher resolution summary of the 4 last plots can be found in Supplemental Information}[.1cm]


\section{Shared SNPs between libraries}
\label{sec:shared}
Shared SNPs between libraries mapped to SR genome v15. The first column shows the count of shared SNPs. The next 3 columns shows the name of the QPX library (\textbf{mmetsp00} 98, 992, 1002, 1433). The libraries situated on a same row share the same SNPs.

<<shared1>>=
shared.snps <- read.table("./data/shared.snps.txt", fill =TRUE)
shared.snps
@ 

Shared indels between libraries mapped to SR genome v15.
\marginnote{\small\color{blue}$\Lsh$ A venn diagram of the shared SNPs can be found in the Manuscript}[.1cm]
<<shared2>>=
shared.indels <- read.table("./data/shared.indels.txt", fill = TRUE)
shared.indels
@ 

\subsection{Component analysis and sequence closeness from MG-RAST annotation}
\label{sec:closeness}
Import annotated data.
<<closeness1>>=
closeness <- read.csv("./data/pca.csv", sep = "\t")
summary(closeness)
closeness <- closeness[, c(1, 7:10)]
@ 

Principal component analysis on 5 libraries, 4 strains and the genome (v15), using an \textit{identity score} for annotating a sequence and an \textit{alignment length score} for similarities with estimated functional features, an \textit{e-value score} for estimated functional similarities, and the \textit{number of hits}, ie., the number of times a function is identified in a library.
<<closeness3>>=
rownames(closeness) <- paste(closeness[, 1], 1:nrow(closeness), sep = ".")
x=closeness[, -1]
head(x)
## standardization (columns)
results <- decostand(x, method = "range")
head(results)
p = princomp(~ avg...ident + avg.align.len
   , data= results)
summary(p)
#plot(p, type = "l")
#biplot(p, cex = .4)
@ 

Clustering and visualization of all sequences without applying any filters.
<<closeness4>>=
ggbiplot(p, obs.scale = 1, 
         var.scale = 1, 
         groups = closeness$metagenome,
         ellipse = TRUE, 
         circle = FALSE) +
        geom_point(aes(size = closeness$X..hits)) +
        theme_bw() +
            theme(legend.direction = 'horizontal', 
                  legend.position = 'top')
@ 

Build a custom PCA function for repetitive iterations.
<<function1>>=
customBiplot <- function(data, method){
x=data[, -1]
results <- decostand(x, method = method)
p = princomp(~ results[, 2] + results[, 3]
   , data= results)
ggbiplot(p, obs.scale = 1, 
         var.scale = 1, 
         groups = data$metagenome,
         ellipse = TRUE, 
         circle = FALSE) +
        theme_bw() +
            theme(legend.direction = 'horizontal', 
                  legend.position = 'top')
}
@

Filter sequences depending on their alignment length and the abundance of an identified function (therotically a protein). 
\marginnote{\small\color{blue}$\Lsh$ results[,2] = identity and results[,3] = alignment length}[.5cm]
<<closeness5>>=
closenessX <- filter(closeness, avg.align.len < 50, X..hits > 2)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Filter by selecting higher alignment scores only.
<<closeness6>>=
closenessX <- filter(closeness, avg.align.len < 60, X..hits > 2)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Select even higher alignment similarities.
<<closeness7>>=
closenessX <- filter(closeness, avg.align.len < 100, X..hits > 4)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Select on the criteria of e-Value and abundance of a functional sequence.
<<closeness8>>=
closenessX <- filter(closeness, avg.eValue < -40, X..hits > 2)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Select on the criteria of e-Value and abundance of a functional sequence.
<<closeness9>>=
closenessX <- filter(closeness, avg.eValue < -40, X..hits > 3)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Select on the criteria of e-Value and abundance of a functional sequence.
<<closeness10>>=
closenessX <- filter(closeness, avg.eValue < -50, X..hits > 2)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 

Select on the criteria of alignment length. Since SNP aggregation tests are the next step in this analysis, the length of a correct alignment is technically helpful in differentiating SNP position. And abundance will be more than 2 to increase probabilities of correct functional annotation.
\marginnote{\small\color{blue}$\Lsh$ This final biplot represent a successful unsupervised clustering of QPX strains. Differences between strains is reflected by the nature of the assembled contigs. But also to the nature of each base pair in these sequences. Top hit contigs N=100}[.1cm]
<<closeness11>>=
closenessX <- filter(closeness, avg.align.len > 200, X..hits >= 2)
dim(closenessX)[1]
customBiplot(closenessX, method = "range")
@ 


\section{Aggregation analysis of SNPS}
\label{sec:aggregations}
MMETSP libraries are already been annotated. How many contigs, peptide and cds elements are indexed?
\marginnote{\small\color{blue}$\Lsh$ Only \textbf{mmetsp} 98, 992, 1002, and 1433 are used in the remaining tests}[.1cm]
<<aggregation1>>=
contigs <- read.xlsx("./data/annot.stats.xlsx", sheetIndex = 1)
contigs <- gather(contigs, "elements", "counts", 2:4)
ggplot(contigs,
       aes(x = factor(library),
           y = counts,
           fill = factor(elements))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() +
            theme(legend.direction = 'horizontal', 
                  legend.position = 'top') + 
                coord_flip() +
                    geom_text(aes(x = factor(library),
                                  y = counts,
                                  ymax = counts,
                                  label = counts,
                                  hjusts = ifelse(sign(counts)> 0,1,0)),
                              position = position_dodge(width = 1)) +
                    labs(x = "Counts",
                         y = "QPX libraries")
@ 

\subsection{Preferential substitution}
\label{sec:preferential}
Preferential substitution of nucleotides. It should be noted that \textit{mmetsp0098} and \textit{mmetsp1433} are both bigger in library size than the others. Therefore comparison of SNPs should be done for each library separately. However there is a resemblance in substitution between libraries since the pattern is quite similar for all nucleotides.
<<preferential1>>=
prefs <- read.table("./data/all.stats.txt")
prefs$V3 <- c(rep("m1002", 12),
              rep("m98", 12),
              rep("m992", 12),
              rep("m1433", 12))
ggplot(prefs,
       aes(x = factor(V1),
           y = V2,
           fill = factor(V3))) + 
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() +
    labs(x = "Nucleotide substitution within called SNPs",
         y = "Counts")
@ 

After hard filtering SNPs to the minimum from all 4 libraries, \textit{DISCARD}-labelled SNPs were removed. The remaining were imported into data frames with the following columns.
\begin{enumerate}
\item CHROM: number of contig
\item POS: SNP position on that contig
\item ALT: alternative SNP to the reference
\item AD: allelic depth for the reference and ALT alleles
\item DP: approximate read depth
\item GQ: genotype quality
\item PL: normalized phred scaled likelihoods
\end{enumerate}
The structure of the data frame is similar to the \textit{iris} data. 
\marginnote{\small\color{blue}$\Lsh$ With low number of sample it is impossible to create a f(SNP)=strain machine learning framework. To make a binary table of SNPs at least 100 samples must be used.}[0.1cm]
<<SNPspred1>>=
x <- c('m98', 'm1433', 'm1002', 'm992')
y <- c(16729, 15267, 9716, 6965)
dat <- data.frame(lib = x, SNPs = y)
ggplot(dat,
       aes(x = lib,
           y = SNPs)) + 
    geom_bar(stat = "identity") +
        theme_bw() + 
            coord_flip() +
                geom_text(aes(x = lib,
                              y = SNPs,
                              ymax = SNPs,
                              label = SNPs,
                              size = 5,
                              col = "white",
                              hjust = 2)) +
                labs(x = "Number of called SNPs with GATK",
                     y = "QPX libraries")
@ 

Import SNP data: data manipulation process of removing NAs and getting the same number of SNPs across all samples.
<<snps12>>=
m98 <- read.table("./data/m98.ml.txt", fill = NA)
m1433 <- read.table("./data/m1433.ml.txt", fill = NA)
m992 <- read.table("./data/m992.ml.txt", fill = NA)
m1002 <- read.table("./data/m1002.ml.txt", fill = NA)

colnames(m98) <- c('contigs', 'pos', 'ad1', 'ad2',
                   'dp', 'gq', 'pl1', 'pl2', 'pl3', 'lib')
colnames(m1433) <- c('contigs', 'pos', 'ad1', 'ad2',
                   'dp', 'gq', 'pl1', 'pl2', 'pl3', 'lib')
colnames(m992) <- c('contigs', 'pos', 'ad1', 'ad2',
                   'dp', 'gq', 'pl1', 'pl2', 'pl3', 'lib')
colnames(m1002) <- c('contigs', 'pos', 'ad1', 'ad2',
                   'dp', 'gq', 'pl1', 'pl2', 'pl3', 'lib')

m98 <- m98[complete.cases(m98), ]
m1433 <- m1433[complete.cases(m1433), ]
m992 <- m992[complete.cases(m992), ]
m1002 <- m1002[complete.cases(m1002), ]

m98 <- m98[! m98$lib != 'm98', ]
m1433 <- m1433[! m1433$lib != 'm1433', ]
m992 <- m992[! m992$lib != 'm992', ]
m1002 <- m1002[! m1002$lib != 'm1002', ]

m1433$pl3 <- as.numeric(m1433$pl3)

m98$lib <- factor(m98$lib, "m98")
m992$lib <- factor(m992$lib, "m992")
m1433$lib <- factor(m1433$lib, "m1433")
m1002$lib <- factor(m1002$lib, "m1002")

index <- min(dim(m98)[1], dim(m1433)[1],
             dim(m992)[1], dim(m1002)[1])
set.seed(123)
mall <- rbind(m98[sample(nrow(m98), index), ],
              m1433[sample(nrow(m1433), index), ],
              m992[sample(nrow(m992), index), ],
              m1002[sample(nrow(m1002), index), ])
dim(mall)
@ 

\subsection{Distribution of SNPs in the QPX libraries}
\label{subsec:available data}
Regressing the genome quality of SNPs on the position of the SNPs inside a contig. This shows that SNPs are concentrated in the first 10 Kb.
<<snpPredict123>>=
head(mall)
with(mall, plot(pos, gq, cex = .5))
@ 

Regression of contigs and the read depth for each SNP in those contigs. When using libraries mapped to the combined assembly (as a reference transcriptome, not showing here) the plot shows that the depth of coverage cat split the SNPs inside the QPX contigs into 2 separate subsets. However the regression is constant when using the genome of SR v15 as a reference for mapping the libraries (as shown below).
<<snpPredict13, out.width='.49\\linewidth', fig.show='hold'>>=
with(mall, plot(contigs, dp, cex = .5))
submall <- filter(mall, dp > 50, pos <= 10000)
@ 

This plot shows that \Sexpr{(nrow(submall)/nrow(mall))*100} \% of the SNPs have a depth over 50 for the first 10 Kb QPX contigs size.
<<snpPredict15>>=
with(mall, plot(pos, dp, cex = .5))
## percentage of SNPs with read depth higher than 35
(nrow(submall)/nrow(mall))*100
@ 

Plotting only SNPs with DP > 50 and in contigs which length <= 10 Kb, and regressing toward a phred-scaled adjusted likelihood for each variant or genotype likelihood.
<<snpPredict16>>=
with(submall, plot(pos, pl1, cex = .5))
summary(submall$lib)
@ 

Linear regression between position of the SNP and the normalized phred scaled likelihood, which on its own is an accuracy determination score. Phred likelihoods (PL) are computed for the REF/REF, REF/ALT, and ALT/ALT variants.
To convert a PL to a raw likelihood L:
\begin{equation}
  \label{eq:3}
  P(L | AA) = 10^{-P_{AA}/10}
\end{equation}
These probabilities are adjusted with phred scores. They determine the probability of a base observed given a reference genotype, an heterozygous genotype or a non-reference genotype respectively (pl1, pl2, and pl3).\\
Accordingly, REF/REF (pl1) is significant. Meaning the genotype we have is homozygous for the reference nucleotide (not the variant), but if a variant exists, thus it represents a rare mutation (\textit{reference needed}). Therefore, the raw likelihoods must be calculated with the equation above for the picked variants and the genotype with \textit{P=1} is the most significant genotype at that nucleotide.
<<nspPredict17, out.width='.49\\linewidth', fig.show='hold'>>=
fit <- lm(pos~pl1, data = submall)
summary(fit)
@ 

Lets get the variants with the highest probability that a genotype has been identified. \textit{PL=1} determines the genotype, either homozygous for REF (pl1) or ALT (pl3) or heterozygous REF/ALT (pl2).
<<snpPredict18>>=
submall[, 7:9] <- apply(submall[, 7:9], 2, function(x) 10^(-x/1000))
head(submall)
@ 

Lets extract all heterozygous alleles with at least 90 \% confidence.
<<snpPredict185>>=
heteromall <- filter(submall, pl2 >= .9)
@ 

The original total number of SNPs was \Sexpr{dim(submall)[1]} among which the total number of variants with an heterozygous genotype is \Sexpr{dim(heteromall)[1]}.
\marginnote{\small\color{blue}$\Lsh$ A summary of the plots in this subsection can be found in the Supplemental Information}[.1cm]
<<snpPredict19>>=
dat <- as.data.frame(summary(heteromall$lib))
ggplot(dat,
       aes(x = rownames(dat),
           y = dat[, 1])) +
    theme_bw() +
        geom_bar(stat = "identity") +
            coord_flip() +
                geom_text(aes(x = rownames(dat),
                              y = dat[, 1],
                              ymax = dat[, 1],
                              size = 5,
                              label = dat[, 1],
                              col = "white",
                              hjust = 2)) +
                labs(x = "Number of heterozygous SNPs",
                     y = "QPX librairies")
@ 

Now lets get the homozygous variants with genotype ALT/ALT with 90 \%.
<<snpPredict20>>=
altmall <- filter(submall, pl3 >= .9)
@ 

The total number of variants ALT/ALT is \Sexpr{dim(altmall)[1]}. Interesting thing is that using the combined assembly as a reference (not showing here), m1433 had also the highest number of homozygous alleles while m98 had half the number shown below.
\marginnote{\small\color{blue}$\Lsh$ The same analysis was done twice with genome reference and the combined assembly as reference}[.1cm]
<<snpPredict21>>=
dat <- as.data.frame(summary(altmall$lib))
ggplot(dat,
       aes(x = rownames(dat), 
           y = dat[, 1])) +
    theme_bw() +
        coord_flip() +
            geom_bar(stat = "identity") +
                geom_text(aes(x = rownames(dat),
                              y = dat[, 1],
                              ymax = dat[, 1],
                              label = dat[, 1],
                              size = 5,
                              color = "white",
                              hjust = 2)) +
                labs(x = "Number of homozygous SNPs",
                     y = "QPX librairies")
@ 

\section{Protein domain annotation}
\label{sec:protein}
Get the number of protein domains that can be predicted from the MMETSP strains. First, assembled contigs must be translated into peptides. HMMER3.2b was used for annotation. Hidden Markov Models were generated on Pfam database. The table below lists old and new annotations against old and new Pfam v26 and v28 libraries. (> 2 years interval between versions).
<<pfam1>>=
pfam <- read.xlsx("./data/pfam.xlsx", sheetIndex = 1)
pfam
@ 

Number of domains found in Pfam v28 for :
\begin{itemize}
\item Virulence
\item Temperature
\item Salinity
\item Salt tolerance
\end{itemize}
<<pfam2>>=
ggplot(pfam[1:4, ],
       aes(x = domain,
           y = pfam)) +
    coord_flip() +
        theme_bw() +
            geom_bar(stat = "identity") +
                geom_text(aes(x = domain,
                              y = pfam,
                              ymax = pfam,
                              label = pfam,
                              size = 5,
                              color = "white",
                              hjust = 2)) +
                labs(x = "Number of domains in each sub library of Pfam",
                     y = "Biological relevance of each Pfam subsets")
@ 

The number of domains that can be estimated from 4 QPX strains. For example if 2 totally different contigs are aligned to one same domain the counter is incremented by 2.
<<pfam3>>=
allpfam <- select(pfam, contains("a"))
allpfam <- filter(allpfam, annot == "new")
allpfam
allpfam <- gather(allpfam[, -2], "lib", "count", 2:5)
ggplot(allpfam,
       aes(x = lib,
           y = count,
           fill = domain)) +
    theme_bw() +
        coord_flip() +
            geom_bar(stat = "identity",
                     position = "dodge") +
                geom_text(aes(x = lib,
                             y = count,
                             ymax = count,
                             label = count,
                             size = 5,
                             hjust = 1),
                              position = position_dodge(width = 1)) +
                labs(x = "Count of identified peptides in Pfam",
                     y = "QPX libraries")
@ 

The \textit{unique} number of domains identified from the alignment. For example, if 2 totally different contigs are aligned to one domain the counter is incremented by 1.
<<pfam4>>=
singlepfam <- select(pfam, contains("s"))
singlepfam <- cbind(singlepfam, X = pfam$domain, Y = pfam$annot)
singlepfam <- filter(singlepfam, Y == "new")
singlepfam <- gather(singlepfam, "lib", "count", 1:4)
ggplot(singlepfam,
       aes(x = X,
           y = count,
           fill = lib)) +
    theme_bw() +
        coord_flip() +
            geom_bar(stat = "identity",
                     position = "dodge") +
                geom_text(aes(x = X,
                              y = count,
                              ymax = count,
                              label = count,
                              size = 5,
                              hjust = 1),
                          position = position_dodge(width = 1)) +
                labs(x = "Count of Pfam domains aligned to QPX peptides",
                     y = "Pfam domain subsets")
@ 

Difference in domain-peptide alignments between old and new pfam databases. Numbers on the right belong to the new Pfam library. Numbers on the left belong to the old Pfam library.
<<pfam5>>=
newpfam <- select(pfam, contains("s"))
newpfam <- cbind(newpfam, annot = pfam$annot, domain = pfam$domain)
newpfam <- gather(newpfam, "lib", "count", 1:4)
ggplot(newpfam,
       aes(x = domain,
           y = count,
           fill = annot,
           group = lib)) +
    theme_bw() +
        coord_flip() +
            geom_bar(stat = "identity",
                     position = "dodge") +
                geom_text(aes(x = domain,
                              y = count,
                              ymax = count,
                              label = count,
                              size = 5,
                              hjust = 1),
                          position = position_dodge(width = 1)) +
                labs(x = "Count of Pfam domains old (left) and new (right) aligned to QPX",
                     y = "Pfam domain subsets")
@ 

Get the number of peptides that match a significant e-value domain.
\marginnote{\small\color{blue}$\Lsh$ The new Pfam library will be used for the remaining tests}[.1cm]
<<pfam6>>=
pfam2 <- read.xlsx("./data/pfam.xlsx", sheetIndex = 2)
pfam2 <- filter(pfam2, annot == "contig")
pfam2 <- gather(pfam2, "evalue", "count", 2:5)
ggplot(pfam2,
       aes(x = pfam,
           y = count,
           fill = evalue,
           group = lib)) +
    theme_bw() +
        geom_bar(stat = "identity",
                 position = "dodge") +
            scale_fill_brewer() +
                coord_flip() +
                    geom_text(aes(x = pfam,
                                  y = count,
                                  ymax = count,
                                  label = count,
                                  size = 4,
                                  hjust = 1),
                              position = position_dodge(width = 1)) +
                    labs(x = "Count of peptides",
                         y = "Pfam domain subsets")
@ 

How many \textit{unique} protein domains were found at different evalue significance.
\marginnote{\small\color{blue}$\Lsh$ A higher resolution summary of these 2 plots can be found in the Manuscript}[.1cm]
<<pfam7>>=
pfam2 <- read.xlsx("./data/pfam.xlsx", sheetIndex = 2)
pfam2 <- filter(pfam2, annot == "domain")
pfam2 <- gather(pfam2, "evalue", "count", 2:5)
ggplot(pfam2,
       aes(x = pfam,
           y = count,
           fill = evalue,
           group = lib)) +
    geom_bar(stat = "identity",
             position = "dodge") +
        scale_fill_brewer() +
            coord_flip() +
                theme_bw() +
                    geom_text(aes(x = pfam,
                                  y = count,
                                  ymax = count,
                                  size = 4,
                                  label = count,
                                  hjust = 1),
                              position = position_dodge(width = 1)) +
                    labs(x = "Count of unique domains",
                         y = "Pfam domain subsets")

@ 

\section{Align assembled contigs to Genome (v15)}
\label{sec:overallstats}
Here is the overall stats of the BLAT of the 4 strains RNA sequenced contigs against SR. genome v15. The QPX contigs have been annotated with pfam. They are aligned to the reference genome for SNP localization. Hence we can identify SNP hotspots inside and outside functional domains.
<<blat1>>=
blat <- read.table("./data/pfam.stats.genomics.txt", header = T)
x <- c("m98", "m992", "m1002", "m1433")
y <- gl(4, 4, 16, labels = c("virulence", "temperature", "salinity", "salt tolerance"))
blat <- data.frame(blat, lib = c(rep(x, 4)), pfam = y)
ggplot(blat,
       aes(x = pfam,
           y = queryCnt,
           fill = lib)) +
    geom_bar(stat = "identity",
             position = "dodge") +
        theme_bw() + 
            coord_flip() +
                scale_fill_brewer() +
                    geom_text(aes(x = pfam,
                                  y = queryCnt,
                                  ymax = queryCnt,
                                  label = queryCnt,
                                  size = 4,
                                  hjust = 1),
                              position = position_dodge(width = 1)) +
                    labs(x = "Number of aligned QPX predicted domains to reference",
                         y = "Pfam subsets")
@ 
From the table data above the \textit{minimum identity} of all contigs aligned is \Sexpr{min(blat$minIdent)}. The \textit{mean query} is necessary to choose the number of contigs mapped. Since each contig can be found multiple times in the genome (at different alignment lengths of course) it is best if we choose the best contigs those that have a maximum alignment length (since the PCA analysis has shown previously that a longer alignment is helpful to distinguishing between strains). Contigs must be mapped/aligned once and thus, no duplicate entries should be selected. For this reason choosing \textbf{an alignment length equal to the half of the mean of the alignment length} gives the minimum number of duplicate contigs.
<<blat2>>=
ggplot(blat,
       aes(x = pfam,
           y = meanQSize,
           fill = lib)) + 
    coord_flip() +
        theme_bw() +
            geom_bar(stat = "identity",
                     position = "dodge") +
                geom_text(aes(x = pfam,
                              y = meanQSize,
                              ymax = meanQSize,
                              label = meanQSize, 
                              size = 4,
                              hjust = 2),
                          position = position_dodge(width = 1)) + 
                labs(x = "Mean of the contigs size with predicted Pfam domains",
                     y = "Pfam subsets")
@ 

\section{Assessing SNP hotspots in 4 QPX strains}
\label{sec:hotspots}
QPX contig assemblies by the MMETSP team were used for pfam annotation (with HMMER). SNP calling on the 4 strains used Steve Roberts reference genome v15 (called with GATK). Location of SNPs in the pfam domains was inferred after alignment of the QPX contigs (those that include a prerdicted functional protein domain) on the reference genome (with BLAT). Finally all data were merged in one file grouped by 4 QPX strains (2 from NY, one from each VA and MA) and 3 pfam subset pathways (Virulence, salinity/salt-tolerance, temperature).
\marginnote{\small\color{blue}$\Lsh$ This summary file includes SNP location on peptide domains and can be traced back to the 4 strains of QPX and the reference genome. This file can be imported into a MySQL database}[.1cm]
<<hotspots1>>=
hotspots.raw <- read.table("./data/hotspots/all.pfam.snp.txt", header = TRUE)
@ 

What is the correlation between a SNP position and the first reference nucleotide that align to a contig containing domain?
<<interaction01>>=
ggplot(hotspots.raw,
       aes(x = Position,
           y = Tstart)) +
    theme_bw() +
        geom_point(aes(color = lib,
                       size = Tsize)) +
            facet_wrap( ~ lib, ncol = 2) +
        labs(x = "Position of SNPs in the reference genome",
             y = "Position of the first aligned nucleotide between contig and reference")

@ 

\marginnote{\small\color{blue}$\Lsh$ A higher resolution version of this plot can be find in the Manuscript}[-.5cm]

How many SNPs can be found inside and outside of protein domains, those of which reside in assembled QPX contigs?
<<hotspots2>>=
count <- c(264, 749, 295)
position <- c("Upstream", "Genic", "Downstream")
dat <- data.frame(position, count)
dat$per <- round((dat$count/sum(dat[, 2]))*100, digits = 2)
ggplot(dat,
       aes(x = position,
           y = count)) +
    theme_bw() +
        geom_bar(stat = "identity") +
            coord_flip() +
                geom_text(aes(x = position,
                              y = count,
                              ymax = count,
                              label = per,
                              size = 4,
                              hjust = 2,
                              color = "white")) +
                labs(x = "Number of SNPs (x axis) and % (bar labels)",
                     y = "Position of SNPs relative to contigs aligned to reference")
@ 

How are SNPs distributed between Pfam subsets? On the chart, the score between parenthesis is the normalized amount of SNPs. It has no units. It is just a score of the normalized counts of SNPs by the number of domains found in each subset. The counts are those of the position of SNPs inside the domains.
<<hotspots3>>=
domain <- c("virulence", "temperature", "salinity", "salt tolerance")
count <- c(467, 306, 64, 347)
dat <- data.frame(domain, count)
dat$norm <- round(dat$count/pfam[1:4, 2], digits = 2)
ggplot(dat,
       aes(x = domain,
           y = count)) +
    theme_bw() +
        coord_flip() +
            geom_bar(stat = "identity") +
                geom_text(aes(x = domain,
                              y = count,
                              ymax = count,
                              label = paste(count, "(x", norm, ")"),
                              size = 3,
                              hjust= .5,
                              color = "white")) +
                labs(x = "Number of SNPs (nb SNPs/nb domains)",
                     y = "Pfam subsets")

@ 

How many SNPs can be found outside of each domain? The outside SNPs can be upstream or downstream the aligned contig over the reference. The SNP position outside the domains is dependent on the Reference contig length, which was selected through alignment.
<<hotspots4>>=
before <- c(155, 160, 11, 126)
after <- c(201, 89, 4, 163)
dat <- data.frame(domain, before, after)
dat <- gather(dat, "location", "count", 2:3)
ggplot(dat,
       aes(x = domain,
           y = count,
           fill = location)) + 
    geom_bar(stat = "identity",
             position = "dodge") + 
        theme_bw() + 
            coord_flip() + 
                geom_text(aes(x = domain,
                              y = count,
                              ymax = count,
                              label = count,
                              size = 3,
                              hjust = 2),
                          position = position_dodge(width = 1)) +
                labs(x = "Number of SNPs",
                     y = "Pfam subsets")
@

How many SNPs can be found inside and outside protein domains within each QPX strain?
<<hotspots5>>=
before <- c(178, 21, 74, 133)
after <- c(177, 15, 69, 189)
inside <- c(593, 73, 216, 448)
strain <- c("m98", "m992", "m1002", "m1433")
dat <- data.frame(strain, before, inside, after)
dat <- gather(dat, "region", "count", 2:4)
ggplot(dat,
       aes(x = strain,
           y = count,
           fill = region)) +
    geom_bar(stat = "identity") +
        geom_text(aes(x = strain,
                      y = count,
                      ymax = count,
                      label = count,
                      vjust = 1,
                      size = 2),
                  position = "stack") +
            theme_bw() +
        labs(x = "QPX libraries",
             y = "SNP counts")
@ 

How many SNPs can be found inside and outside domains between virulence, temperature, salinity and within strain?
<<hotspots6>>=
dat <- read.xlsx("./data/hotspots/snps.all.pfam.xlsx", sheetIndex = 1)
dat <- gather(dat, "region", "count", 3:5)
ggplot(dat,
       aes(x = lib,
           y = count,
           fill = region)) + 
    geom_bar(stat = "identity") +
        geom_text(aes(x = lib,
                      y = count,
                      ymax = count,
                      label = count,
                      size = 1,
                      hjust = .5),
                  position = "stack") +
            facet_wrap( ~ pfam, ncol = 2) + 
                theme_bw() + 
                    scale_fill_hue(c = 40, l = 60) +
                labs(x = "QPX libraries",
                     y = "SNP counts")

@ 

Preferential substitution inside/outside domains, per Pfam subset, and for each strain.
<<hotspots7, out.width='1.2\\linewidth'>>=
dat <- read.xlsx("./data/hotspots/snps.all.pfam.xlsx", sheetIndex = 2)
dat <- gather(dat, "mutation", "count", 3:14)
dat$mutation <- gsub(".", ">", dat$mutation, fixed = TRUE)
dat$pfam <- factor(dat$pfam, levels = c("virulence",
                                        "temperature",
                                        "salt.tolerance",
                                        "salinity"))
dat$lib <- factor(dat$lib, levels = c("m98",
                                      "m1002", "m1433", "m992"))
ggplot(dat,
       aes(x = mutation,
           y = count,
           fill = region)) +
    geom_bar(stat = "identity") +
            theme_bw() +
                facet_wrap(lib ~ pfam, ncol = 4) +
                    scale_fill_hue(c = 40,  l = 60) +
                labs(x = "Nucleotide substitution within called SNPs",
                     y = "SNP count")
@ 


Frequency of SNPs inside Pfam domains for each strain, per 1 Kbp. Normalized by the total size of contigs for each strain.
<<hotspots9>>=
dat <- read.xlsx("./data/hotspots/snps.all.pfam.xlsx", sheetIndex = 1)
inside <- c(593, 73, 216, 448)
sizen <- c(425098, 46409, 242136, 337206)
dat$inside <- with(dat, (inside/tsum)*1000)
ggplot(dat,
       aes(x = lib,
           y = inside)) + 
    geom_bar(stat = "identity") +
        geom_text(aes(x = lib,
                      y = inside,
                      ymax = inside,
                      label = round(inside, digits = 2),
                      size = 1,
                      color = "white",
                      vjust = 1.5)) +
            facet_wrap( ~ pfam, ncol = 2) + 
                theme_bw()

@ 


\section{Machine learning on SNP hotspots of 4 QPX strains}
\label{subsec:mlqpx}
Lets try a support vector machine classifier to differentiate between the QPX strains using quality data (above) of the variants.
In progress ... 

\section{System Information}
\label{sec:sys_info}
\noindent
The version number of R and packages loaded for generating the vignette were:
<<sessionInfo>>=
###save(list=ls(pattern=".*|.*"),file="PD.Rdata")
sessionInfo()
@ 



\end{linenumbers}

\end{document}
